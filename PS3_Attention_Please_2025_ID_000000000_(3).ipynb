{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royrubel152/-israel-trade-dashboard/blob/main/PS3_Attention_Please_2025_ID_000000000_(3).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOpGoE2T-YXS"
      },
      "source": [
        "# Neural Machine Translation with Attention\n",
        "\n",
        "Advanced Learning Fall 2025\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For SUBMISSION:   \n",
        "\n",
        "Please upload the complete and executed `ipynb` to your git repository. Verify that all of your output can be viewed directly from github, and provide a link to that git file below.\n",
        "\n",
        "~~~\n",
        "STUDENT ID: 322950148\n",
        "~~~\n",
        "\n",
        "~~~\n",
        "STUDENT GIT LINK: MISSING\n",
        "~~~\n",
        "In Addition, don't forget to add your ID to the files, and upload to moodle the html version:    \n",
        "  \n",
        "`PS3_Attention_2025_ID_[000000000].html`   \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PpJdYve9cZa6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eecp2PAf7qJq"
      },
      "source": [
        "In this problem set we are going to jump into the depths of `seq2seq` and `attention` and build a couple of PyTorch translation mechanisms with some  twists.     \n",
        "\n",
        "\n",
        "*   Part 1 consists of a somewhat unorthodox `seq2seq` model for simple arithmetics\n",
        "*   Part 2 consists of an `seq2seq - attention` language translation model. We will use it for Hebrew and English.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "-VpUCez9gOZn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajNDsL5HlZN6"
      },
      "source": [
        "A **seq2seq** model (sequence-to-sequence model) is a type of neural network designed specifically to handle sequences of data. The model converts input sequences into other sequences of data. This makes them particularly useful for tasks involving language, where the input and output are naturally sequences of words.\n",
        "\n",
        "Here's a breakdown of how `seq2seq` models work:\n",
        "\n",
        "* The encoder takes the input sequence, like a sentence in English, and processes it to capture its meaning and context.\n",
        "\n",
        "* information is then passed to the decoder, which uses it to generate the output sequence, like a translation in French.\n",
        "\n",
        "* Attention mechanism (optional): Some `seq2seq` models also incorporate an attention mechanism. This allows the decoder to focus on specific parts of the input sequence that are most relevant to generating the next element in the output sequence.\n",
        "\n",
        "`seq2seq` models are used in many natural language processing (NLP) tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbUDn4FObol7"
      },
      "source": [
        "imports: (feel free to add)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "crTe33wcD_Eg"
      },
      "outputs": [],
      "source": [
        "# from __future__ import unicode_literals, print_function, division\n",
        "# from io import open\n",
        "# import unicodedata\n",
        "import re\n",
        "import random\n",
        "import unicodedata\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TV9hBMKuqCF",
        "outputId": "d71eb1b7-f1f6-453c-d81e-bbebb1d3754b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec 30 19:27:19 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiwtNgENbx2g"
      },
      "source": [
        "## Part 1: Seq2Seq Arithmetic model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1gWov3Gx67I"
      },
      "source": [
        "**Using RNN `seq2seq` model to \"learn\" simple arithmetics!**\n",
        "\n",
        "> Given the string \"54-7\", the model should return a prediction: \"47\".  \n",
        "> Given the string \"10+20\", the model should return a prediction: \"30\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxo92ZgTy6ED"
      },
      "source": [
        "- Watch Lukas Biewald's short [video](https://youtu.be/MqugtGD605k?si=rAH34ZTJyYDj-XJ1) explaining `seq2seq` models and his toy application (somewhat outdated).\n",
        "- You can find the code for his example [here](https://github.com/lukas/ml-class/blob/master/videos/seq2seq/train.py).    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEu_5YvqFPai"
      },
      "source": [
        "1.1) Using Lukas' code, implement a `seq2seq` network that can learn how to solve **addition AND substraction** of two numbers of maximum length of 4, using the following steps (similar to the example):      \n",
        "\n",
        "* Generate data; X: queries (two numbers), and Y: answers   \n",
        "* One-hot encode X and Y,\n",
        "* Build a `seq2seq` network (with LSTM, RepeatVector, and TimeDistributed layers)\n",
        "* Train the model.\n",
        "* While training, sample from the validation set at random so we can visualize the generated solutions against the true solutions.    \n",
        "\n",
        "Notes:  \n",
        "* The code in the example is quite old and based on Keras. You might have to adapt some of the code to overcome methods/code that is not supported anymore. Hint: for the evaluation part, review the type and format of the \"correct\" output - this will help you fix the unsupported \"model.predict_classes\".\n",
        "* Please use the parameters in the code cell below to train the model.     \n",
        "* Instead of using a `wandb.config` object, please use a simple dictionary instead.   \n",
        "* You don't need to run the model for more than 50 iterations (epochs) to get a gist of what is happening and what the algorithm is doing.\n",
        "* Extra credit if you can implement the network in PyTorch (this is not difficult).    \n",
        "* Extra credit if you are able to significantly improve the model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 — Imports + GPU check"
      ],
      "metadata": {
        "id": "5rMvKodbw-Uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"GPU available:\", len(tf.config.list_physical_devices('GPU')) > 0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMDy9zUtu91D",
        "outputId": "9adb7a9e-66ae-4023-8ded-b645fe37db2b"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.19.0\n",
            "GPU available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 — Config dictionary"
      ],
      "metadata": {
        "id": "A14SuTz5w8dc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"training_size\": 50000,\n",
        "    \"digits\": 4,              # max digits per number\n",
        "    \"hidden_size\": 128,\n",
        "    \"batch_size\": 128,\n",
        "    \"epochs\": 50\n",
        "}\n"
      ],
      "metadata": {
        "id": "QrYE6HCNvSav"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3 — CharacterTable"
      ],
      "metadata": {
        "id": "psmIEHMWw6UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CharacterTable:\n",
        "    def __init__(self, chars):\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = {c: i for i, c in enumerate(self.chars)}\n",
        "        self.indices_char = {i: c for i, c in enumerate(self.chars)}\n",
        "\n",
        "    def encode(self, s, maxlen):\n",
        "        x = np.zeros((maxlen, len(self.chars)), dtype=bool)\n",
        "        for i, c in enumerate(s):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x):\n",
        "        # x: (T, V) probabilities OR one-hot\n",
        "        x = x.argmax(axis=-1)\n",
        "        return ''.join(self.indices_char[i] for i in x)\n"
      ],
      "metadata": {
        "id": "UgVUWg3tvZOY"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4 — Generate data (addition AND subtraction)"
      ],
      "metadata": {
        "id": "NCOw05uFw1yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digits = config[\"digits\"]\n",
        "\n",
        "maxlen_in  = digits + 1 + digits          # e.g. \"1234+5678\" -> 9 chars\n",
        "maxlen_out = digits + 2                   # allow sign + up to 5 digits (e.g. -9999 or 19998)\n",
        "\n",
        "chars = \"0123456789+- \"                   # includes space padding\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "def generate_pair():\n",
        "    a = random.randint(0, 10**digits - 1)\n",
        "    b = random.randint(0, 10**digits - 1)\n",
        "    op = random.choice([\"+\", \"-\"])\n",
        "    q = f\"{a}{op}{b}\"\n",
        "    q = q + \" \" * (maxlen_in - len(q))\n",
        "\n",
        "    y = str(a + b) if op == \"+\" else str(a - b)\n",
        "    y = y + \" \" * (maxlen_out - len(y))\n",
        "    return q, y\n",
        "\n",
        "questions, expected = [], []\n",
        "seen = set()\n",
        "\n",
        "while len(questions) < config[\"training_size\"]:\n",
        "    q, y = generate_pair()\n",
        "\n",
        "    # Optional: reduce duplicates\n",
        "    if q in seen:\n",
        "        continue\n",
        "    seen.add(q)\n",
        "\n",
        "    questions.append(q)\n",
        "    expected.append(y)\n",
        "\n",
        "print(\"Sample:\")\n",
        "for i in range(5):\n",
        "    print(questions[i], \"=>\", expected[i])\n",
        "print(\"maxlen_in:\", maxlen_in, \"| maxlen_out:\", maxlen_out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQR8Y4EnvfaO",
        "outputId": "f8d1fd0c-c9ff-45bd-bf37-99244d098c92"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample:\n",
            "7361-8251 => -890  \n",
            "5343+230  => 5573  \n",
            "7153-7489 => -336  \n",
            "8982-4329 => 4653  \n",
            "2882-1496 => 1386  \n",
            "maxlen_in: 9 | maxlen_out: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5 — One-hot encode X and Y"
      ],
      "metadata": {
        "id": "ziDFFTM-wxYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(questions), maxlen_in,  len(chars)), dtype=bool)\n",
        "y = np.zeros((len(expected),  maxlen_out, len(chars)), dtype=bool)\n",
        "\n",
        "for i, q in enumerate(questions):\n",
        "    x[i] = ctable.encode(q, maxlen_in)\n",
        "\n",
        "for i, ans in enumerate(expected):\n",
        "    y[i] = ctable.encode(ans, maxlen_out)\n",
        "\n",
        "# Shuffle\n",
        "idx = np.arange(len(x))\n",
        "np.random.shuffle(idx)\n",
        "x, y = x[idx], y[idx]\n",
        "\n",
        "# Train/Val split (90/10)\n",
        "split_at = int(0.9 * len(x))\n",
        "x_train, x_val = x[:split_at], x[split_at:]\n",
        "y_train, y_val = y[:split_at], y[split_at:]\n",
        "\n",
        "print(\"Train:\", x_train.shape, y_train.shape)\n",
        "print(\"Val:  \", x_val.shape, y_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmFJrF0vvi9k",
        "outputId": "463eb679-00d5-4b4a-f80c-f94a54a77147"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (45000, 9, 13) (45000, 6, 13)\n",
            "Val:   (5000, 9, 13) (5000, 6, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6 — Build Seq2Seq model"
      ],
      "metadata": {
        "id": "g8QYpN6nwtUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    LSTM(config[\"hidden_size\"], input_shape=(maxlen_in, len(chars))),\n",
        "    RepeatVector(maxlen_out),\n",
        "    LSTM(config[\"hidden_size\"], return_sequences=True),\n",
        "    TimeDistributed(Dense(len(chars), activation=\"softmax\"))\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "AY-6mPiLvsHA",
        "outputId": "94ca410e-7f14-43f0-893a-3bc56ecc4a6f"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m72,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ repeat_vector_4 (\u001b[38;5;33mRepeatVector\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m13\u001b[0m)          │         \u001b[38;5;34m1,677\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">72,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ repeat_vector_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,677</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m205,965\u001b[0m (804.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205,965</span> (804.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m205,965\u001b[0m (804.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205,965</span> (804.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7 — Train + sample predictions each epoch\n"
      ],
      "metadata": {
        "id": "dEokazUewibK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_onehot_or_probs(arr2d):\n",
        "    # arr2d shape: (T, V)\n",
        "    return ctable.decode(arr2d).strip()\n",
        "\n",
        "for epoch in range(1, config[\"epochs\"] + 1):\n",
        "    hist = model.fit(\n",
        "        x_train, y_train,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        epochs=1,\n",
        "        validation_data=(x_val, y_val),\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    train_loss = hist.history[\"loss\"][0]\n",
        "    val_loss   = hist.history[\"val_loss\"][0]\n",
        "    val_acc    = hist.history[\"val_accuracy\"][0]\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | loss={train_loss:.4f} | val_loss={val_loss:.4f} | val_acc={val_acc:.4f}\")\n",
        "\n",
        "    # show a few random validation examples\n",
        "    for _ in range(3):\n",
        "        i = np.random.randint(0, len(x_val))\n",
        "        q = decode_onehot_or_probs(x_val[i])\n",
        "        true = decode_onehot_or_probs(y_val[i])\n",
        "\n",
        "        pred_probs = model.predict(x_val[i:i+1], verbose=0)[0]\n",
        "        pred = decode_onehot_or_probs(pred_probs)\n",
        "\n",
        "        ok = \"✅\" if pred == true else \"❌\"\n",
        "        print(f\"  Q: {q} | T: {true} | P: {pred} {ok}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZFq-3yzvvi6",
        "outputId": "b3080a8d-e3b6-4e87-b32f-fb8c15f952ea"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | loss=1.8318 | val_loss=1.6774 | val_acc=0.3964\n",
            "  Q: 5209+9354 | T: 14563 | P: 1122 ❌\n",
            "  Q: 468+8210 | T: 8678 | P: 1122 ❌\n",
            "  Q: 5740+131 | T: 5871 | P: 1222 ❌\n",
            "Epoch 02 | loss=1.6284 | val_loss=1.5832 | val_acc=0.4103\n",
            "  Q: 8379-9565 | T: -1186 | P: -214 ❌\n",
            "  Q: 3541-1223 | T: 2318 | P: 214 ❌\n",
            "  Q: 1896-9100 | T: -7204 | P: -5744 ❌\n",
            "Epoch 03 | loss=1.5372 | val_loss=1.5009 | val_acc=0.4423\n",
            "  Q: 239-65 | T: 174 | P: 229 ❌\n",
            "  Q: 9343+9552 | T: 18895 | P: 17555 ❌\n",
            "  Q: 9595+396 | T: 9991 | P: 9025 ❌\n",
            "Epoch 04 | loss=1.4734 | val_loss=1.4438 | val_acc=0.4579\n",
            "  Q: 6832+2502 | T: 9334 | P: 9001 ❌\n",
            "  Q: 8976-2141 | T: 6835 | P: 5521 ❌\n",
            "  Q: 7000+7210 | T: 14210 | P: 13901 ❌\n",
            "Epoch 05 | loss=1.4258 | val_loss=1.4111 | val_acc=0.4670\n",
            "  Q: 7015-8963 | T: -1948 | P: -116 ❌\n",
            "  Q: 1038-678 | T: 360 | P: 113 ❌\n",
            "  Q: 5580-8284 | T: -2704 | P: -2199 ❌\n",
            "Epoch 06 | loss=1.3924 | val_loss=1.3730 | val_acc=0.4874\n",
            "  Q: 8871-6090 | T: 2781 | P: 2656 ❌\n",
            "  Q: 3258-375 | T: 2883 | P: 3364 ❌\n",
            "  Q: 9035+4778 | T: 13813 | P: 13556 ❌\n",
            "Epoch 07 | loss=1.3621 | val_loss=1.3491 | val_acc=0.4899\n",
            "  Q: 3235+4133 | T: 7368 | P: 7666 ❌\n",
            "  Q: 4829-2539 | T: 2290 | P: 2356 ❌\n",
            "  Q: 5787+229 | T: 6016 | P: 5566 ❌\n",
            "Epoch 08 | loss=1.3417 | val_loss=1.3317 | val_acc=0.4984\n",
            "  Q: 4748-7877 | T: -3129 | P: -3456 ❌\n",
            "  Q: 2571-7396 | T: -4825 | P: -5115 ❌\n",
            "  Q: 7944+9690 | T: 17634 | P: 18055 ❌\n",
            "Epoch 09 | loss=1.3236 | val_loss=1.3189 | val_acc=0.5000\n",
            "  Q: 4489+3438 | T: 7927 | P: 8407 ❌\n",
            "  Q: 3535+634 | T: 4169 | P: 5000 ❌\n",
            "  Q: 2535-7521 | T: -4986 | P: -4100 ❌\n",
            "Epoch 10 | loss=1.3056 | val_loss=1.2977 | val_acc=0.5120\n",
            "  Q: 6850-4964 | T: 1886 | P: 1116 ❌\n",
            "  Q: 2250+6899 | T: 9149 | P: 9011 ❌\n",
            "  Q: 678-900 | T: -222 | P: -16 ❌\n",
            "Epoch 11 | loss=1.2895 | val_loss=1.2839 | val_acc=0.5154\n",
            "  Q: 8280+4065 | T: 12345 | P: 12112 ❌\n",
            "  Q: 2601+6708 | T: 9309 | P: 9012 ❌\n",
            "  Q: 1913-6122 | T: -4209 | P: -4122 ❌\n",
            "Epoch 12 | loss=1.2763 | val_loss=1.2730 | val_acc=0.5180\n",
            "  Q: 6875+2528 | T: 9403 | P: 9016 ❌\n",
            "  Q: 69-7973 | T: -7904 | P: -8486 ❌\n",
            "  Q: 1531-1850 | T: -319 | P: -123 ❌\n",
            "Epoch 13 | loss=1.2657 | val_loss=1.2586 | val_acc=0.5256\n",
            "  Q: 7330-1461 | T: 5869 | P: 5641 ❌\n",
            "  Q: 4499+6517 | T: 11016 | P: 11466 ❌\n",
            "  Q: 5057+9068 | T: 14125 | P: 13961 ❌\n",
            "Epoch 14 | loss=1.2608 | val_loss=1.2587 | val_acc=0.5181\n",
            "  Q: 7778+4930 | T: 12708 | P: 12448 ❌\n",
            "  Q: 9177-9596 | T: -419 | P: -106 ❌\n",
            "  Q: 9742+6921 | T: 16663 | P: 16972 ❌\n",
            "Epoch 15 | loss=1.2432 | val_loss=1.2332 | val_acc=0.5352\n",
            "  Q: 4318-109 | T: 4209 | P: 5111 ❌\n",
            "  Q: 1753+4064 | T: 5817 | P: 5848 ❌\n",
            "  Q: 9875+9939 | T: 19814 | P: 19119 ❌\n",
            "Epoch 16 | loss=1.2395 | val_loss=1.3024 | val_acc=0.5064\n",
            "  Q: 7638+4722 | T: 12360 | P: 11618 ❌\n",
            "  Q: 2421+1721 | T: 4142 | P: 4804 ❌\n",
            "  Q: 3861-1723 | T: 2138 | P: 2614 ❌\n",
            "Epoch 17 | loss=1.2316 | val_loss=1.2204 | val_acc=0.5396\n",
            "  Q: 6847-2452 | T: 4395 | P: 4441 ❌\n",
            "  Q: 9524-3211 | T: 6313 | P: 6449 ❌\n",
            "  Q: 7683-7475 | T: 208 | P: 11 ❌\n",
            "Epoch 18 | loss=1.2272 | val_loss=1.2311 | val_acc=0.5307\n",
            "  Q: 2996+1090 | T: 4086 | P: 4205 ❌\n",
            "  Q: 6168+3148 | T: 9316 | P: 9269 ❌\n",
            "  Q: 1507+7822 | T: 9329 | P: 9269 ❌\n",
            "Epoch 19 | loss=1.2173 | val_loss=1.2203 | val_acc=0.5383\n",
            "  Q: 2484+3426 | T: 5910 | P: 5859 ❌\n",
            "  Q: 6978+1140 | T: 8118 | P: 8005 ❌\n",
            "  Q: 1176-7911 | T: -6735 | P: -6795 ❌\n",
            "Epoch 20 | loss=1.2057 | val_loss=1.2128 | val_acc=0.5422\n",
            "  Q: 1645+7866 | T: 9511 | P: 9409 ❌\n",
            "  Q: 9258-7528 | T: 1730 | P: 1748 ❌\n",
            "  Q: 8635+7775 | T: 16410 | P: 16244 ❌\n",
            "Epoch 21 | loss=1.2059 | val_loss=1.2125 | val_acc=0.5379\n",
            "  Q: 793+6049 | T: 6842 | P: 6624 ❌\n",
            "  Q: 1519+6478 | T: 7997 | P: 8788 ❌\n",
            "  Q: 9479-7527 | T: 1952 | P: 1248 ❌\n",
            "Epoch 22 | loss=1.1966 | val_loss=1.2138 | val_acc=0.5333\n",
            "  Q: 9610-9590 | T: 20 | P: -2 ❌\n",
            "  Q: 5739+4749 | T: 10488 | P: 10522 ❌\n",
            "  Q: 3727-6109 | T: -2382 | P: -2622 ❌\n",
            "Epoch 23 | loss=1.1862 | val_loss=1.1951 | val_acc=0.5467\n",
            "  Q: 6155-3509 | T: 2646 | P: 2466 ❌\n",
            "  Q: 7991+4484 | T: 12475 | P: 12600 ❌\n",
            "  Q: 8686+369 | T: 9055 | P: 9206 ❌\n",
            "Epoch 24 | loss=1.1782 | val_loss=1.1745 | val_acc=0.5530\n",
            "  Q: 7473+9877 | T: 17350 | P: 17352 ❌\n",
            "  Q: 267-594 | T: -327 | P: -210 ❌\n",
            "  Q: 3348-6792 | T: -3444 | P: -3521 ❌\n",
            "Epoch 25 | loss=1.1687 | val_loss=1.1651 | val_acc=0.5571\n",
            "  Q: 7463-102 | T: 7361 | P: 7007 ❌\n",
            "  Q: 7775+9442 | T: 17217 | P: 17196 ❌\n",
            "  Q: 6001-6861 | T: -860 | P: -313 ❌\n",
            "Epoch 26 | loss=1.1604 | val_loss=1.1653 | val_acc=0.5517\n",
            "  Q: 7532-9319 | T: -1787 | P: -1620 ❌\n",
            "  Q: 9055+7352 | T: 16407 | P: 16201 ❌\n",
            "  Q: 9832+5251 | T: 15083 | P: 15100 ❌\n",
            "Epoch 27 | loss=1.1464 | val_loss=1.1492 | val_acc=0.5608\n",
            "  Q: 6349+1126 | T: 7475 | P: 7663 ❌\n",
            "  Q: 7017+8827 | T: 15844 | P: 15706 ❌\n",
            "  Q: 3306+198 | T: 3504 | P: 2044 ❌\n",
            "Epoch 28 | loss=1.1346 | val_loss=1.1405 | val_acc=0.5624\n",
            "  Q: 8441+5329 | T: 13770 | P: 13744 ❌\n",
            "  Q: 3861-1723 | T: 2138 | P: 2848 ❌\n",
            "  Q: 5367-9902 | T: -4535 | P: -4538 ❌\n",
            "Epoch 29 | loss=1.1222 | val_loss=1.1224 | val_acc=0.5674\n",
            "  Q: 8576-8957 | T: -381 | P: -469 ❌\n",
            "  Q: 8317-803 | T: 7514 | P: 7281 ❌\n",
            "  Q: 3396-749 | T: 2647 | P: 2207 ❌\n",
            "Epoch 30 | loss=1.1092 | val_loss=1.1014 | val_acc=0.5776\n",
            "  Q: 2567-2060 | T: 507 | P: 113 ❌\n",
            "  Q: 4918+5562 | T: 10480 | P: 10423 ❌\n",
            "  Q: 9252+8572 | T: 17824 | P: 17851 ❌\n",
            "Epoch 31 | loss=1.0933 | val_loss=1.0938 | val_acc=0.5784\n",
            "  Q: 856+9052 | T: 9908 | P: 9806 ❌\n",
            "  Q: 2873-6150 | T: -3277 | P: -3363 ❌\n",
            "  Q: 4854-2373 | T: 2481 | P: 2563 ❌\n",
            "Epoch 32 | loss=1.0805 | val_loss=1.0734 | val_acc=0.5867\n",
            "  Q: 8480-2462 | T: 6018 | P: 6219 ❌\n",
            "  Q: 1982-4902 | T: -2920 | P: -2991 ❌\n",
            "  Q: 6271+2902 | T: 9173 | P: 9422 ❌\n",
            "Epoch 33 | loss=1.0671 | val_loss=1.0578 | val_acc=0.5947\n",
            "  Q: 7162-1673 | T: 5489 | P: 5581 ❌\n",
            "  Q: 8874-3614 | T: 5260 | P: 5531 ❌\n",
            "  Q: 2388-428 | T: 1960 | P: 1553 ❌\n",
            "Epoch 34 | loss=1.0497 | val_loss=1.0491 | val_acc=0.5938\n",
            "  Q: 9904+5486 | T: 15390 | P: 15492 ❌\n",
            "  Q: 6371+8158 | T: 14529 | P: 14691 ❌\n",
            "  Q: 395-7705 | T: -7310 | P: -7322 ❌\n",
            "Epoch 35 | loss=1.0327 | val_loss=1.0364 | val_acc=0.5985\n",
            "  Q: 4626-1618 | T: 3008 | P: 3064 ❌\n",
            "  Q: 706+2933 | T: 3639 | P: 3831 ❌\n",
            "  Q: 6037-2594 | T: 3443 | P: 3422 ❌\n",
            "Epoch 36 | loss=1.0166 | val_loss=1.0208 | val_acc=0.6074\n",
            "  Q: 7934+927 | T: 8861 | P: 9636 ❌\n",
            "  Q: 418-69 | T: 349 | P: 143 ❌\n",
            "  Q: 5571-1940 | T: 3631 | P: 3860 ❌\n",
            "Epoch 37 | loss=1.0024 | val_loss=1.0107 | val_acc=0.6135\n",
            "  Q: 7639-5781 | T: 1858 | P: 1919 ❌\n",
            "  Q: 4018+8731 | T: 12749 | P: 12619 ❌\n",
            "  Q: 7465-6478 | T: 987 | P: 103 ❌\n",
            "Epoch 38 | loss=0.9920 | val_loss=0.9958 | val_acc=0.6189\n",
            "  Q: 1345+6062 | T: 7407 | P: 7464 ❌\n",
            "  Q: 5155-7482 | T: -2327 | P: -2471 ❌\n",
            "  Q: 6179+7675 | T: 13854 | P: 13819 ❌\n",
            "Epoch 39 | loss=0.9806 | val_loss=0.9802 | val_acc=0.6279\n",
            "  Q: 4989+6984 | T: 11973 | P: 11991 ❌\n",
            "  Q: 2004-5722 | T: -3718 | P: -3730 ❌\n",
            "  Q: 6244-8808 | T: -2564 | P: -2600 ❌\n",
            "Epoch 40 | loss=0.9698 | val_loss=0.9932 | val_acc=0.6198\n",
            "  Q: 2018+6968 | T: 8986 | P: 9022 ❌\n",
            "  Q: 8737-6865 | T: 1872 | P: 1922 ❌\n",
            "  Q: 4225-2127 | T: 2098 | P: 2122 ❌\n",
            "Epoch 41 | loss=0.9602 | val_loss=0.9750 | val_acc=0.6243\n",
            "  Q: 7465-6478 | T: 987 | P: 902 ❌\n",
            "  Q: 7321+1041 | T: 8362 | P: 8422 ❌\n",
            "  Q: 5821+4865 | T: 10686 | P: 10622 ❌\n",
            "Epoch 42 | loss=0.9514 | val_loss=0.9596 | val_acc=0.6327\n",
            "  Q: 3760+9791 | T: 13551 | P: 13526 ❌\n",
            "  Q: 1734+5718 | T: 7452 | P: 7486 ❌\n",
            "  Q: 9265-3393 | T: 5872 | P: 5847 ❌\n",
            "Epoch 43 | loss=0.9433 | val_loss=0.9578 | val_acc=0.6310\n",
            "  Q: 2973+6626 | T: 9599 | P: 9649 ❌\n",
            "  Q: 9676-836 | T: 8840 | P: 8993 ❌\n",
            "  Q: 5966+3848 | T: 9814 | P: 9872 ❌\n",
            "Epoch 44 | loss=0.9380 | val_loss=0.9515 | val_acc=0.6351\n",
            "  Q: 9384+5996 | T: 15380 | P: 15382 ❌\n",
            "  Q: 2349+4287 | T: 6636 | P: 6629 ❌\n",
            "  Q: 3130-3771 | T: -641 | P: -621 ❌\n",
            "Epoch 45 | loss=0.9291 | val_loss=0.9395 | val_acc=0.6404\n",
            "  Q: 6172+315 | T: 6487 | P: 6400 ❌\n",
            "  Q: 2030-393 | T: 1637 | P: 1350 ❌\n",
            "  Q: 6686+3380 | T: 10066 | P: 10040 ❌\n",
            "Epoch 46 | loss=0.9223 | val_loss=0.9455 | val_acc=0.6357\n",
            "  Q: 2520-7025 | T: -4505 | P: -4514 ❌\n",
            "  Q: 1279-6318 | T: -5039 | P: -5096 ❌\n",
            "  Q: 7872+8292 | T: 16164 | P: 16066 ❌\n",
            "Epoch 47 | loss=0.9160 | val_loss=0.9417 | val_acc=0.6369\n",
            "  Q: 4823+6456 | T: 11279 | P: 11293 ❌\n",
            "  Q: 4254-7373 | T: -3119 | P: -3096 ❌\n",
            "  Q: 3036+4424 | T: 7460 | P: 7465 ❌\n",
            "Epoch 48 | loss=0.9126 | val_loss=0.9295 | val_acc=0.6426\n",
            "  Q: 2401+3230 | T: 5631 | P: 5673 ❌\n",
            "  Q: 7316+799 | T: 8115 | P: 7127 ❌\n",
            "  Q: 523+6593 | T: 7116 | P: 7177 ❌\n",
            "Epoch 49 | loss=0.9070 | val_loss=0.9302 | val_acc=0.6446\n",
            "  Q: 9037-3895 | T: 5142 | P: 5188 ❌\n",
            "  Q: 2574+9754 | T: 12328 | P: 12333 ❌\n",
            "  Q: 5993+7143 | T: 13136 | P: 13188 ❌\n",
            "Epoch 50 | loss=0.9029 | val_loss=0.9207 | val_acc=0.6478\n",
            "  Q: 5407-8732 | T: -3325 | P: -3388 ❌\n",
            "  Q: 7739+8640 | T: 16379 | P: 16386 ❌\n",
            "  Q: 7429-7647 | T: -218 | P: -193 ❌\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of Baseline Results\n",
        "We trained a standard seq2seq LSTM model on 4-digit addition and subtraction for 50 epochs. Here is a breakdown of what the data tells us.\n",
        "\n",
        "1. The \"Illusion\" of Accuracy\n",
        "At first glance, the metrics look somewhat promising, but they are misleading:\n",
        "\n",
        "Character Accuracy (~64%): The model is getting about 2 out of every 3 keystrokes correct. This means it has learned the syntax of the problem (e.g., \"The answer should be a number,\" \"It should be about 5 digits long,\" \"If there's a minus sign, the answer might be negative\").\n",
        "\n",
        "Exact Match Accuracy (0.64%): This is the real story. Out of 5,000 validation equations, the model only got about 32 completely right.\n",
        "\n",
        "2. Why is it failing?\n",
        "If we look at the predictions from Epoch 50, we can see a clear pattern:\n",
        "\n",
        "Query: 7739+8640\n",
        "\n",
        "True Answer: 16379\n",
        "\n",
        "Prediction: 16386\n",
        "\n",
        "The model got the first three digits (163) correct but failed on the last two. This happens because standard LSTMs read inputs Left-to-Right, but mathematical operations (like carrying the 1) happen Right-to-Left. By the time the LSTM reads the end of the sequence, it has \"forgotten\" the exact details needed to calculate the final digits.\n",
        "\n",
        "3. Conclusion\n",
        "The baseline model is functioning like a student who is guessing answers based on how the numbers \"look\" rather than actually calculating them. It successfully learned the format of the task, but the architecture (without attention or reversed inputs) is too simple to learn the logic of arithmetic carries over long sequences.\n",
        "\n",
        "Next Step: We will attempt to fix this by reversing the input string, which"
      ],
      "metadata": {
        "id": "xx7bZLbH-0Gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate_model(model, x, y, ctable):\n",
        "    # 1. Generate predictions for the entire validation set\n",
        "    print(\"Predicting on validation set...\")\n",
        "    preds_probs = model.predict(x, verbose=0)\n",
        "\n",
        "    # 2. Convert one-hot predictions and targets back to indices (integers)\n",
        "    # Shape becomes: (num_samples, maxlen_out)\n",
        "    preds_indices = np.argmax(preds_probs, axis=-1)\n",
        "    y_indices = np.argmax(y, axis=-1)\n",
        "\n",
        "    correct_char_count = 0\n",
        "    total_char_count = 0\n",
        "    perfect_matches = 0\n",
        "\n",
        "    # 3. Iterate through every sample to decode and compare strings\n",
        "    for i in range(len(x)):\n",
        "        # Decode prediction and truth\n",
        "        # We join characters and .strip() to remove padding spaces\n",
        "        pred_str = \"\".join([ctable.indices_char[idx] for idx in preds_indices[i]]).strip()\n",
        "        true_str = \"\".join([ctable.indices_char[idx] for idx in y_indices[i]]).strip()\n",
        "\n",
        "        # Check for Exact Match (Sequence Level)\n",
        "        if pred_str == true_str:\n",
        "            perfect_matches += 1\n",
        "\n",
        "        # Check for Character Level Accuracy (Manually)\n",
        "        # (This should match the 'val_accuracy' reported by Keras closely)\n",
        "        # We compare raw indices including padding for strict comparison\n",
        "        matches = (preds_indices[i] == y_indices[i])\n",
        "        correct_char_count += np.sum(matches)\n",
        "        total_char_count += len(matches)\n",
        "\n",
        "    # 4. Calculate final metrics\n",
        "    exact_match_acc = perfect_matches / len(x)\n",
        "    char_acc = correct_char_count / total_char_count\n",
        "\n",
        "    return exact_match_acc, char_acc\n",
        "\n",
        "# Run the evaluation\n",
        "exact_acc, char_acc = evaluate_model(model, x_val, y_val, ctable)\n",
        "\n",
        "print(\"-\" * 30)\n",
        "print(f\"Validation Size:       {len(x_val)}\")\n",
        "print(f\"Character Accuracy:    {char_acc:.2%}\")\n",
        "print(f\"Exact Match Accuracy:  {exact_acc:.2%}\")\n",
        "print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cs8ESlj8wkW",
        "outputId": "ae088e06-8e02-4fba-d0ac-e14055efcde8"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting on validation set...\n",
            "------------------------------\n",
            "Validation Size:       5000\n",
            "Character Accuracy:    64.78%\n",
            "Exact Match Accuracy:  0.64%\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 2: Reversed Input Sequence\n",
        "\n",
        "In this experiment, we apply a well-known optimization trick for Seq2Seq models: **Reversing the Input**.\n",
        "\n",
        "**Hypothesis:** By feeding the input string in reverse (e.g., changing `12+34` to `43+21`), we shorten the \"distance\" between the start of the input and the start of the output. This makes it easier for the LSTM to maintain long-term dependencies, theoretically improving accuracy without changing the model architecture."
      ],
      "metadata": {
        "id": "GmNsCvKM_TjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions_rev, answers_rev = [], []\n",
        "\n",
        "while len(questions_rev) < config[\"training_size\"]:\n",
        "    a = random.randint(0, 10**digits - 1)\n",
        "    b = random.randint(0, 10**digits - 1)\n",
        "    op = random.choice([\"+\", \"-\"])\n",
        "\n",
        "    q = f\"{a}{op}{b}\"[::-1]\n",
        "    q = q + \" \" * (maxlen_in - len(q))\n",
        "\n",
        "    y = str(a + b) if op == \"+\" else str(a - b)\n",
        "    y = y + \" \" * (maxlen_out - len(y))\n",
        "\n",
        "    questions_rev.append(q)\n",
        "    answers_rev.append(y)\n",
        "\n",
        "print(\"Example reversed input:\", questions_rev[0], \"→\", answers_rev[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYzBrdykvzOH",
        "outputId": "6871d46b-88f6-4da6-9fe8-0c8e2f2bfdfd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example reversed input: 878+4168  → 9492  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Generate Reversed Data\n",
        "questions_rev, answers_rev = [], []\n",
        "\n",
        "# Use the same config from previous cells\n",
        "print(f\"Generating {config['training_size']} reversed samples...\")\n",
        "\n",
        "while len(questions_rev) < config[\"training_size\"]:\n",
        "    a = random.randint(0, 10**config[\"digits\"] - 1)\n",
        "    b = random.randint(0, 10**config[\"digits\"] - 1)\n",
        "    op = random.choice([\"+\", \"-\"])\n",
        "\n",
        "\n",
        "    # \"12+34\" becomes \"43+21\"\n",
        "    q = f\"{a}{op}{b}\"[::-1]\n",
        "\n",
        "    # Pad to fixed length\n",
        "    q = q + \" \" * (maxlen_in - len(q))\n",
        "\n",
        "    # Calculate true answer (Keep output normal!)\n",
        "    y = str(a + b) if op == \"+\" else str(a - b)\n",
        "    y = y + \" \" * (maxlen_out - len(y))\n",
        "\n",
        "    questions_rev.append(q)\n",
        "    answers_rev.append(y)\n",
        "\n",
        "print(\"Example reversed input:\", questions_rev[0], \"→\", answers_rev[0])\n",
        "\n",
        "# 2. Vectorize (One-Hot Encoding)\n",
        "# CHANGED: dtype=bool -> dtype='float32' for stability\n",
        "x_rev = np.zeros((len(questions_rev), maxlen_in, len(chars)), dtype='float32')\n",
        "y_rev = np.zeros((len(answers_rev),  maxlen_out, len(chars)), dtype='float32')\n",
        "\n",
        "for i, q in enumerate(questions_rev):\n",
        "    x_rev[i] = ctable.encode(q, maxlen_in)\n",
        "\n",
        "for i, a in enumerate(answers_rev):\n",
        "    y_rev[i] = ctable.encode(a, maxlen_out)\n",
        "\n",
        "# 3. Shuffle and Split\n",
        "idx = np.arange(len(x_rev))\n",
        "np.random.shuffle(idx)\n",
        "x_rev, y_rev = x_rev[idx], y_rev[idx]\n",
        "\n",
        "split = int(0.9 * len(x_rev))\n",
        "x_rev_train, x_rev_val = x_rev[:split], x_rev[split:]\n",
        "y_rev_train, y_rev_val = y_rev[:split], y_rev[split:]\n",
        "\n",
        "print(\"Train:\", x_rev_train.shape, y_rev_train.shape)\n",
        "print(\"Val:  \", x_rev_val.shape, y_rev_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkkxieuF_Zup",
        "outputId": "6ee9671e-a33b-4b8b-ec90-3951443c8584"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating 50000 reversed samples...\n",
            "Example reversed input: 8939+7095 → 15305 \n",
            "Train: (45000, 9, 13) (45000, 6, 13)\n",
            "Val:   (5000, 9, 13) (5000, 6, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Setup\n",
        "We re-initialize the exact same LSTM architecture as the baseline to ensure a fair comparison. The only variable changing is the data order."
      ],
      "metadata": {
        "id": "_4tNIxrY_lfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_reverse = Sequential([\n",
        "    LSTM(config[\"hidden_size\"], input_shape=(maxlen_in, len(chars))),\n",
        "    RepeatVector(maxlen_out),\n",
        "    LSTM(config[\"hidden_size\"], return_sequences=True),\n",
        "    TimeDistributed(Dense(len(chars), activation=\"softmax\"))\n",
        "])\n",
        "\n",
        "model_reverse.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model_reverse.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "psVluca2_kaO",
        "outputId": "82256cf7-359d-48a1-9aa5-8b82af1b2ccd"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m72,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ repeat_vector_5 (\u001b[38;5;33mRepeatVector\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m13\u001b[0m)          │         \u001b[38;5;34m1,677\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">72,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ repeat_vector_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,677</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m205,965\u001b[0m (804.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205,965</span> (804.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m205,965\u001b[0m (804.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205,965</span> (804.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop\n",
        "We train for the same number of epochs (50). Watch the `val_accuracy` and sample predictions. You should notice the model learning the arithmetic logic much faster than the baseline."
      ],
      "metadata": {
        "id": "gW9thgmv_uS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper to decode one-hot back to string\n",
        "def decode(arr2d):\n",
        "    return ctable.decode(arr2d).strip()\n",
        "\n",
        "print(\"Starting training with REVERSED inputs...\")\n",
        "\n",
        "for epoch in range(1, config[\"epochs\"] + 1):\n",
        "    hist = model_reverse.fit(\n",
        "        x_rev_train, y_rev_train,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        epochs=1,\n",
        "        validation_data=(x_rev_val, y_rev_val),\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch:02d} | \"\n",
        "        f\"loss={hist.history['loss'][0]:.4f} | \"\n",
        "        f\"val_loss={hist.history['val_loss'][0]:.4f} | \"\n",
        "        f\"val_acc={hist.history['val_accuracy'][0]:.4f}\"\n",
        "    )\n",
        "\n",
        "    # Visualize 3 random samples\n",
        "    if epoch % 5 == 0: # Print samples every 5 epochs to reduce clutter\n",
        "        print(\"--- Sample Predictions ---\")\n",
        "        for _ in range(3):\n",
        "            i = np.random.randint(len(x_rev_val))\n",
        "            q = decode(x_rev_val[i])\n",
        "            t = decode(y_rev_val[i])\n",
        "            p = decode(model_reverse.predict(x_rev_val[i:i+1], verbose=0)[0])\n",
        "\n",
        "            mark = \"✅\" if p == t else \"❌\"\n",
        "            print(f\"  Q(rev): {q} | True: {t} | Pred: {p} {mark}\")\n",
        "        print(\"--------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaFGl1Go_rZ9",
        "outputId": "b2f50877-2f52-4a0b-9618-7ce39c344749"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training with REVERSED inputs...\n",
            "Epoch 01 | loss=1.8255 | val_loss=1.6701 | val_acc=0.3994\n",
            "Epoch 02 | loss=1.6212 | val_loss=1.5619 | val_acc=0.4145\n",
            "Epoch 03 | loss=1.5292 | val_loss=1.5053 | val_acc=0.4281\n",
            "Epoch 04 | loss=1.4681 | val_loss=1.4389 | val_acc=0.4706\n",
            "Epoch 05 | loss=1.4217 | val_loss=1.3969 | val_acc=0.4853\n",
            "--- Sample Predictions ---\n",
            "  Q(rev): 1622-7535 | True: 3096 | Pred: 3891 ❌\n",
            "  Q(rev): 073+6943 | True: 3866 | Pred: 5611 ❌\n",
            "  Q(rev): 0388-3308 | True: -797 | Pred: -110 ❌\n",
            "--------------------------\n",
            "Epoch 06 | loss=1.3878 | val_loss=1.3683 | val_acc=0.4985\n",
            "Epoch 07 | loss=1.3603 | val_loss=1.3488 | val_acc=0.4997\n",
            "Epoch 08 | loss=1.3411 | val_loss=1.3255 | val_acc=0.5089\n",
            "Epoch 09 | loss=1.3265 | val_loss=1.3125 | val_acc=0.5084\n",
            "Epoch 10 | loss=1.3071 | val_loss=1.2986 | val_acc=0.5172\n",
            "--- Sample Predictions ---\n",
            "  Q(rev): 0461+3634 | True: 6003 | Pred: 6112 ❌\n",
            "  Q(rev): 3231-2852 | True: 1259 | Pred: 1208 ❌\n",
            "  Q(rev): 1375-1399 | True: 4200 | Pred: 4888 ❌\n",
            "--------------------------\n",
            "Epoch 11 | loss=1.2936 | val_loss=1.2828 | val_acc=0.5218\n",
            "Epoch 12 | loss=1.2767 | val_loss=1.2738 | val_acc=0.5276\n",
            "Epoch 13 | loss=1.2615 | val_loss=1.2626 | val_acc=0.5263\n",
            "Epoch 14 | loss=1.2439 | val_loss=1.2366 | val_acc=0.5398\n",
            "Epoch 15 | loss=1.2253 | val_loss=1.2218 | val_acc=0.5450\n",
            "--- Sample Predictions ---\n",
            "  Q(rev): 6074-8801 | True: -3618 | Pred: -3315 ❌\n",
            "  Q(rev): 4572-5657 | True: 4811 | Pred: 4815 ❌\n",
            "  Q(rev): 7637-2883 | True: -3485 | Pred: -3315 ❌\n",
            "--------------------------\n",
            "Epoch 16 | loss=1.2089 | val_loss=1.2007 | val_acc=0.5541\n",
            "Epoch 17 | loss=1.1885 | val_loss=1.1725 | val_acc=0.5619\n",
            "Epoch 18 | loss=1.1578 | val_loss=1.1494 | val_acc=0.5661\n",
            "Epoch 19 | loss=1.1279 | val_loss=1.1196 | val_acc=0.5787\n",
            "Epoch 20 | loss=1.0972 | val_loss=1.0909 | val_acc=0.5934\n",
            "--- Sample Predictions ---\n",
            "  Q(rev): 0673+2786 | True: 10632 | Pred: 10631 ❌\n",
            "  Q(rev): 8739-7213 | True: -6251 | Pred: -6099 ❌\n",
            "  Q(rev): 2122-7484 | True: 2635 | Pred: 2646 ❌\n",
            "--------------------------\n",
            "Epoch 21 | loss=1.0690 | val_loss=1.0502 | val_acc=0.6094\n",
            "Epoch 22 | loss=1.0342 | val_loss=1.0232 | val_acc=0.6195\n",
            "Epoch 23 | loss=1.0055 | val_loss=0.9964 | val_acc=0.6299\n",
            "Epoch 24 | loss=0.9780 | val_loss=0.9728 | val_acc=0.6423\n",
            "Epoch 25 | loss=0.9597 | val_loss=0.9612 | val_acc=0.6416\n",
            "--- Sample Predictions ---\n",
            "  Q(rev): 781-298 | True: 705 | Pred: 961 ❌\n",
            "  Q(rev): 3098-9309 | True: 136 | Pred: 109 ❌\n",
            "  Q(rev): 8031+8936 | True: 7706 | Pred: 7666 ❌\n",
            "--------------------------\n",
            "Epoch 26 | loss=0.9424 | val_loss=0.9452 | val_acc=0.6505\n",
            "Epoch 27 | loss=0.9277 | val_loss=0.9373 | val_acc=0.6470\n",
            "Epoch 28 | loss=0.9132 | val_loss=0.9279 | val_acc=0.6566\n",
            "Epoch 29 | loss=0.9003 | val_loss=0.9101 | val_acc=0.6598\n",
            "Epoch 30 | loss=0.8873 | val_loss=0.8925 | val_acc=0.6695\n",
            "--- Sample Predictions ---\n",
            "  Q(rev): 3687+6842 | True: 10349 | Pred: 10322 ❌\n",
            "  Q(rev): 6274+8491 | True: 6674 | Pred: 6624 ❌\n",
            "  Q(rev): 9194+1845 | True: 10400 | Pred: 10399 ❌\n",
            "--------------------------\n",
            "Epoch 31 | loss=0.8788 | val_loss=0.8841 | val_acc=0.6692\n",
            "Epoch 32 | loss=0.8620 | val_loss=0.8792 | val_acc=0.6716\n",
            "Epoch 33 | loss=0.8515 | val_loss=0.8536 | val_acc=0.6806\n",
            "Epoch 34 | loss=0.8332 | val_loss=0.8607 | val_acc=0.6751\n",
            "Epoch 35 | loss=0.8153 | val_loss=0.8162 | val_acc=0.6952\n",
            "--- Sample Predictions ---\n",
            "  Q(rev): 12-881 | True: 167 | Pred: 20 ❌\n",
            "  Q(rev): 3082+8399 | True: 12741 | Pred: 12728 ❌\n",
            "  Q(rev): 7383-1869 | True: 5844 | Pred: 5828 ❌\n",
            "--------------------------\n",
            "Epoch 36 | loss=0.7952 | val_loss=0.7993 | val_acc=0.7028\n",
            "Epoch 37 | loss=0.7684 | val_loss=0.8006 | val_acc=0.6973\n",
            "Epoch 38 | loss=0.7494 | val_loss=0.7614 | val_acc=0.7132\n",
            "Epoch 39 | loss=0.7218 | val_loss=0.7435 | val_acc=0.7224\n",
            "Epoch 40 | loss=0.6985 | val_loss=0.7037 | val_acc=0.7338\n",
            "--- Sample Predictions ---\n",
            "  Q(rev): 7261-669 | True: -661 | Pred: -663 ❌\n",
            "  Q(rev): 3332-4658 | True: 6231 | Pred: 6225 ❌\n",
            "  Q(rev): 4775+7371 | True: 7511 | Pred: 7518 ❌\n",
            "--------------------------\n",
            "Epoch 41 | loss=0.6787 | val_loss=0.6762 | val_acc=0.7441\n",
            "Epoch 42 | loss=0.6402 | val_loss=0.6541 | val_acc=0.7550\n",
            "Epoch 43 | loss=0.6148 | val_loss=0.6287 | val_acc=0.7642\n",
            "Epoch 44 | loss=0.5943 | val_loss=0.6052 | val_acc=0.7723\n",
            "Epoch 45 | loss=0.5756 | val_loss=0.5885 | val_acc=0.7796\n",
            "--- Sample Predictions ---\n",
            "  Q(rev): 0629-3998 | True: -267 | Pred: -275 ❌\n",
            "  Q(rev): 9507+6398 | True: 15995 | Pred: 16998 ❌\n",
            "  Q(rev): 7155-6476 | True: 1229 | Pred: 1238 ❌\n",
            "--------------------------\n",
            "Epoch 46 | loss=0.5626 | val_loss=0.5798 | val_acc=0.7849\n",
            "Epoch 47 | loss=0.5458 | val_loss=0.5659 | val_acc=0.7914\n",
            "Epoch 48 | loss=0.5414 | val_loss=0.6568 | val_acc=0.7589\n",
            "Epoch 49 | loss=0.5324 | val_loss=0.5456 | val_acc=0.7959\n",
            "Epoch 50 | loss=0.5169 | val_loss=0.5399 | val_acc=0.7987\n",
            "--- Sample Predictions ---\n",
            "  Q(rev): 3559-1967 | True: -1862 | Pred: -1865 ❌\n",
            "  Q(rev): 1199-3522 | True: -7658 | Pred: -7656 ❌\n",
            "  Q(rev): 2514+7771 | True: 5929 | Pred: 5929 ✅\n",
            "--------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Evaluation and Analysis\n",
        "We calculate the **Exact Match Accuracy** to see how many equations were solved perfectly.\n",
        "Analysis: Experiment 2 (Reversed Input)1. Performance ImprovementReversing the input sequence yielded significant gains over the baseline model.Character Accuracy: Increased from ~65% to 79.87%.Exact Match Accuracy: Rose from ~0.6% to 7.92%.While exact matches remain low, the model is now solving ~400 validation equations perfectly compared to the baseline's ~35.2. Mechanism of ActionMathematical operations like addition rely heavily on the least significant digits (the \"ones\" column). Reversing the input (e.g., 12+34 $\\rightarrow$ 43+21) feeds these critical digits to the LSTM first. This aligns the input data more closely with the logic required for the output, reducing the \"distance\" the network must bridge to learn carry operations.3. Error Analysis: The Memory BottleneckThe model exhibits a specific failure mode where it correctly predicts the magnitude but fails on the final digits.Example: True Answer: -1862 vs. Prediction: -1865Cause: The \"ones\" digits are processed at step 1 (due to reversal) but are needed for the final character of the output. The LSTM struggles to retain this specific information across the entire generation sequence.ConclusionReversing inputs proves that data order is critical for LSTMs. However, the plateau at ~80% accuracy indicates the model is limited by the fixed context vector bottleneck—it essentially \"forgets\" the early inputs by the time it finishes the output. Solving this requires an Attention mechanism."
      ],
      "metadata": {
        "id": "DDBqlwg2_8AQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_full_metrics(model, x, y, ctable):\n",
        "    print(\"Predicting full validation set...\")\n",
        "    preds = model.predict(x, verbose=0)\n",
        "\n",
        "    # Argmax to get indices (Integers)\n",
        "    p_idx = np.argmax(preds, axis=-1)\n",
        "    y_idx = np.argmax(y, axis=-1)\n",
        "\n",
        "    # 1. Calculate Character Accuracy (vectorized)\n",
        "    # Compare every single digit/character across the entire array\n",
        "    correct_chars = np.sum(p_idx == y_idx)\n",
        "    total_chars = p_idx.size\n",
        "    char_acc = correct_chars / total_chars\n",
        "\n",
        "    # 2. Calculate Exact Match Accuracy (loop)\n",
        "    perfect_count = 0\n",
        "    total_samples = len(x)\n",
        "\n",
        "    for i in range(total_samples):\n",
        "        # Decode strings to remove padding and compare\n",
        "        p_str = \"\".join([ctable.indices_char[c] for c in p_idx[i]]).strip()\n",
        "        t_str = \"\".join([ctable.indices_char[c] for c in y_idx[i]]).strip()\n",
        "\n",
        "        if p_str == t_str:\n",
        "            perfect_count += 1\n",
        "\n",
        "    exact_match_acc = perfect_count / total_samples\n",
        "    return char_acc, exact_match_acc\n",
        "\n",
        "# Run Evaluation\n",
        "char_score, exact_score = evaluate_full_metrics(model_reverse, x_rev_val, y_rev_val, ctable)\n",
        "\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(f\"REVERSED INPUT RESULTS\")\n",
        "print(f\"Character Accuracy:   {char_score:.2%}\")\n",
        "print(f\"Exact Match Accuracy: {exact_score:.2%}\")\n",
        "print(\"=\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76MGfC98_0yD",
        "outputId": "ea5d119b-a697-433a-d678-2ca47d4fa691"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting full validation set...\n",
            "\n",
            "==============================\n",
            "REVERSED INPUT RESULTS\n",
            "Character Accuracy:   79.87%\n",
            "Exact Match Accuracy: 7.92%\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 3: Attention Mechanism\n",
        "\n",
        "In this  experiment, we add an **Attention Layer**. This allows the Decoder to \"look back\" at the entire input sequence and focus on specific digits (like the ones column) exactly when needed, rather than relying on a single \"memory vector.\"\n",
        "\n",
        "**Architecture Changes:**\n",
        "1. **Encoder:** Returns the *full sequence* of states, not just the last one.\n",
        "2. **Attention:** Computes a weighted average of the Encoder outputs based on the Decoder's current state.\n",
        "3. **Concatenate:** Merges the Attention context with the Decoder's state to make the final prediction."
      ],
      "metadata": {
        "id": "BM7Wi32TB2x7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed, Attention, Concatenate\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "3ywTjfccDxm1"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import (\n",
        "    Input, LSTM, Dense, RepeatVector,\n",
        "    TimeDistributed, Attention, Concatenate\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# =====================\n",
        "# Encoder\n",
        "# =====================\n",
        "encoder_inputs = Input(shape=(maxlen_in, len(chars)))\n",
        "\n",
        "encoder_outputs, state_h, state_c = LSTM(\n",
        "    config[\"hidden_size\"],\n",
        "    return_sequences=True,\n",
        "    return_state=True\n",
        ")(encoder_inputs)\n",
        "\n",
        "# =====================\n",
        "# Decoder\n",
        "# =====================\n",
        "decoder_inputs = RepeatVector(maxlen_out)(state_h)\n",
        "\n",
        "decoder_outputs = LSTM(\n",
        "    config[\"hidden_size\"],\n",
        "    return_sequences=True\n",
        ")(\n",
        "    decoder_inputs,\n",
        "    initial_state=[state_h, state_c]\n",
        ")\n",
        "\n",
        "# =====================\n",
        "# Attention\n",
        "# =====================\n",
        "context = Attention()([decoder_outputs, encoder_outputs])\n",
        "\n",
        "decoder_combined = Concatenate()([decoder_outputs, context])\n",
        "\n",
        "# =====================\n",
        "# Output\n",
        "# =====================\n",
        "outputs = TimeDistributed(\n",
        "    Dense(len(chars), activation=\"softmax\")\n",
        ")(decoder_combined)\n",
        "\n",
        "model_attention = Model(encoder_inputs, outputs)\n",
        "\n",
        "model_attention.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model_attention.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "VHBatgFYy2nQ",
        "outputId": "59483b8d-fa72-4595-e4b7-e573b97c20e4"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m13\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_22 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m),  │     \u001b[38;5;34m72,704\u001b[0m │ input_layer_11[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │                   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ repeat_vector_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_23 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │    \u001b[38;5;34m131,584\u001b[0m │ repeat_vector_11… │\n",
              "│                     │                   │            │ lstm_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],    │\n",
              "│                     │                   │            │ lstm_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lstm_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed_11 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m13\u001b[0m)     │      \u001b[38;5;34m3,341\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">72,704</span> │ input_layer_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │                   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ repeat_vector_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ repeat_vector_11… │\n",
              "│                     │                   │            │ lstm_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],    │\n",
              "│                     │                   │            │ lstm_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lstm_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed_11 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,341</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m207,629\u001b[0m (811.05 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">207,629</span> (811.05 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m207,629\u001b[0m (811.05 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">207,629</span> (811.05 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Analysis: Experiment 3 (Reversed + Attention)\n",
        "\n",
        "### 1. Results Overview\n",
        "This experiment combined **Input Reversal** with a standard **Attention Mechanism**. The results show a massive leap in performance compared to the previous architectures.\n",
        "\n",
        "| Metric | Baseline | Reversed Only | **Reversed + Attention** |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **Exact Match Accuracy** | 0.64% | 7.92% | **75.06%** |\n",
        "\n",
        "The model correctly solved over **3,750 out of 5,000** equations. This confirms that the Attention mechanism is the single most important component for this task."
      ],
      "metadata": {
        "id": "5KI86Hl9MBaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_attention\n",
        "x_tr, y_tr = x_rev_train, y_rev_train\n",
        "x_va, y_va = x_rev_val, y_rev_val\n",
        "\n",
        "def decode(arr2d):\n",
        "    return ctable.decode(arr2d).strip()\n",
        "\n",
        "for epoch in range(1, config[\"epochs\"] + 1):\n",
        "    hist = model.fit(\n",
        "        x_tr, y_tr,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        epochs=1,\n",
        "        validation_data=(x_va, y_va),\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch:02d} | \"\n",
        "        f\"loss={hist.history['loss'][0]:.4f} | \"\n",
        "        f\"val_loss={hist.history['val_loss'][0]:.4f} | \"\n",
        "        f\"val_acc={hist.history['val_accuracy'][0]:.4f}\"\n",
        "    )\n",
        "\n",
        "    for _ in range(3):\n",
        "        i = np.random.randint(len(x_va))\n",
        "        q = decode(x_va[i])\n",
        "        t = decode(y_va[i])\n",
        "        p = decode(model.predict(x_va[i:i+1], verbose=0)[0])\n",
        "\n",
        "        mark = \"✅\" if p == t else \"❌\"\n",
        "        print(f\"  Q: {q} | T: {t} | P: {p} {mark}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSrUTs9Gy47T",
        "outputId": "6ecc20e4-daf3-4610-c192-963742bb7396"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | loss=1.7680 | val_loss=1.6483 | val_acc=0.4031\n",
            "  Q: 0592-1821 | T: -1669 | P: -399 ❌\n",
            "  Q: 9568-8412 | T: -6511 | P: -119 ❌\n",
            "  Q: 8447+8789 | T: 17326 | P: 11318 ❌\n",
            "Epoch 02 | loss=1.6063 | val_loss=1.5526 | val_acc=0.4102\n",
            "  Q: 8882+4984 | T: 7782 | P: 1011 ❌\n",
            "  Q: 741-7047 | T: 7260 | P: 4183 ❌\n",
            "  Q: 5773+6346 | T: 10211 | P: 1024 ❌\n",
            "Epoch 03 | loss=1.5192 | val_loss=1.4719 | val_acc=0.4526\n",
            "  Q: 9676+1544 | T: 11220 | P: 10222 ❌\n",
            "  Q: 569+081 | T: 1145 | P: 8111 ❌\n",
            "  Q: 8045-2525 | T: -156 | P: -10 ❌\n",
            "Epoch 04 | loss=1.4541 | val_loss=1.4491 | val_acc=0.4587\n",
            "  Q: 9004-1307 | T: 3022 | P: 3333 ❌\n",
            "  Q: 4923+411 | T: 3408 | P: 3333 ❌\n",
            "  Q: 3312+8402 | T: 4181 | P: 5736 ❌\n",
            "Epoch 05 | loss=1.4045 | val_loss=1.3947 | val_acc=0.4853\n",
            "  Q: 3019+8154 | T: 13621 | P: 13299 ❌\n",
            "  Q: 3294-6522 | T: -2667 | P: -2199 ❌\n",
            "  Q: 0324-3455 | T: 1313 | P: 121 ❌\n",
            "Epoch 06 | loss=1.3695 | val_loss=1.3580 | val_acc=0.4939\n",
            "  Q: 2614-6897 | T: 3824 | P: 2222 ❌\n",
            "  Q: 0712+2089 | T: 11972 | P: 12288 ❌\n",
            "  Q: 5309-6092 | T: -6129 | P: -6222 ❌\n",
            "Epoch 07 | loss=1.3451 | val_loss=1.3587 | val_acc=0.4871\n",
            "  Q: 2601+5044 | T: 5467 | P: 6322 ❌\n",
            "  Q: 8504+9369 | T: 13697 | P: 14344 ❌\n",
            "  Q: 4309-5086 | T: -2229 | P: -2221 ❌\n",
            "Epoch 08 | loss=1.3206 | val_loss=1.3053 | val_acc=0.5175\n",
            "  Q: 4221-1076 | T: 5477 | P: 5455 ❌\n",
            "  Q: 737-8421 | T: 511 | P: 140 ❌\n",
            "  Q: 1032-8878 | T: 6487 | P: 6455 ❌\n",
            "Epoch 09 | loss=1.3013 | val_loss=1.2937 | val_acc=0.5254\n",
            "  Q: 6585-1614 | T: -1695 | P: -1250 ❌\n",
            "  Q: 6465-4664 | T: -982 | P: -111 ❌\n",
            "  Q: 9375-162 | T: -5478 | P: -5150 ❌\n",
            "Epoch 10 | loss=1.2786 | val_loss=1.2702 | val_acc=0.5277\n",
            "  Q: 0601+538 | T: 1895 | P: 2413 ❌\n",
            "  Q: 9808+7199 | T: 18006 | P: 18753 ❌\n",
            "  Q: 9733+8113 | T: 6497 | P: 6553 ❌\n",
            "Epoch 11 | loss=1.2577 | val_loss=1.2541 | val_acc=0.5328\n",
            "  Q: 0539+2652 | T: 11912 | P: 12196 ❌\n",
            "  Q: 8646-6356 | T: 68 | P: -5 ❌\n",
            "  Q: 8344-6447 | T: 3008 | P: 3009 ❌\n",
            "Epoch 12 | loss=1.2354 | val_loss=1.2286 | val_acc=0.5411\n",
            "  Q: 7119-4931 | T: -7723 | P: -7350 ❌\n",
            "  Q: 4751-1654 | T: 2987 | P: 2238 ❌\n",
            "  Q: 6945+5585 | T: 11351 | P: 11232 ❌\n",
            "Epoch 13 | loss=1.2099 | val_loss=1.2065 | val_acc=0.5514\n",
            "  Q: 2027+5668 | T: 15867 | P: 15999 ❌\n",
            "  Q: 9862-0579 | T: 7061 | P: 7000 ❌\n",
            "  Q: 7347-2857 | T: 145 | P: 119 ❌\n",
            "Epoch 14 | loss=1.1831 | val_loss=1.1714 | val_acc=0.5637\n",
            "  Q: 893-5899 | T: 9587 | P: 9311 ❌\n",
            "  Q: 033-8105 | T: 4688 | P: 4111 ❌\n",
            "  Q: 6168+2956 | T: 15208 | P: 15213 ❌\n",
            "Epoch 15 | loss=1.1491 | val_loss=1.1344 | val_acc=0.5712\n",
            "  Q: 1081+5757 | T: 9376 | P: 9563 ❌\n",
            "  Q: 8972+7488 | T: 11645 | P: 11634 ❌\n",
            "  Q: 6173-4004 | T: 288 | P: 139 ❌\n",
            "Epoch 16 | loss=1.1070 | val_loss=1.0938 | val_acc=0.5864\n",
            "  Q: 7373-5267 | T: 3888 | P: 3088 ❌\n",
            "  Q: 8078-7844 | T: -4221 | P: -4333 ❌\n",
            "  Q: 8959-7428 | T: -1351 | P: -1323 ❌\n",
            "Epoch 17 | loss=1.0641 | val_loss=1.1029 | val_acc=0.5760\n",
            "  Q: 0699+7201 | T: 10987 | P: 11815 ❌\n",
            "  Q: 8126-2323 | T: -2986 | P: -2990 ❌\n",
            "  Q: 7637+5537 | T: 14722 | P: 15733 ❌\n",
            "Epoch 18 | loss=1.0015 | val_loss=0.9673 | val_acc=0.6380\n",
            "  Q: 2468+1993 | T: 12633 | P: 12534 ❌\n",
            "  Q: 2236+1667 | T: 13983 | P: 13993 ❌\n",
            "  Q: 3144-8067 | T: 3195 | P: 3355 ❌\n",
            "Epoch 19 | loss=0.9354 | val_loss=0.9154 | val_acc=0.6589\n",
            "  Q: 5192-9962 | T: -216 | P: -333 ❌\n",
            "  Q: 6644+2315 | T: 9598 | P: 9698 ❌\n",
            "  Q: 7471+1065 | T: 7348 | P: 7347 ❌\n",
            "Epoch 20 | loss=0.8693 | val_loss=0.8651 | val_acc=0.6670\n",
            "  Q: 2196-0016 | T: -812 | P: -691 ❌\n",
            "  Q: 7301+2987 | T: 8929 | P: 8839 ❌\n",
            "  Q: 6484-612 | T: -4630 | P: -4692 ❌\n",
            "Epoch 21 | loss=0.8153 | val_loss=0.8067 | val_acc=0.7016\n",
            "  Q: 8268-3368 | T: 5 | P: -1 ❌\n",
            "  Q: 8474+5113 | T: 7863 | P: 7864 ❌\n",
            "  Q: 904-8408 | T: 7639 | P: 8799 ❌\n",
            "Epoch 22 | loss=0.7666 | val_loss=0.7674 | val_acc=0.7125\n",
            "  Q: 614-2721 | T: 856 | P: 187 ❌\n",
            "  Q: 7262+7887 | T: 10514 | P: 10423 ❌\n",
            "  Q: 6524+1463 | T: 7897 | P: 7887 ❌\n",
            "Epoch 23 | loss=0.7189 | val_loss=0.7295 | val_acc=0.7342\n",
            "  Q: 9963-9222 | T: -1470 | P: -1399 ❌\n",
            "  Q: 0136+478 | T: 7184 | P: 7184 ✅\n",
            "  Q: 572-7621 | T: 992 | P: 100 ❌\n",
            "Epoch 24 | loss=0.6829 | val_loss=0.6595 | val_acc=0.7681\n",
            "  Q: 3433+2377 | T: 11075 | P: 11065 ❌\n",
            "  Q: 1516-9419 | T: 2998 | P: 2077 ❌\n",
            "  Q: 6644+2315 | T: 9598 | P: 9598 ✅\n",
            "Epoch 25 | loss=0.6285 | val_loss=0.6360 | val_acc=0.7740\n",
            "  Q: 9338+3379 | T: 18072 | P: 18072 ✅\n",
            "  Q: 736+8722 | T: 2915 | P: 2865 ❌\n",
            "  Q: 1349+9415 | T: 14580 | P: 14580 ✅\n",
            "Epoch 26 | loss=0.5903 | val_loss=0.6036 | val_acc=0.7922\n",
            "  Q: 9364-1889 | T: 5242 | P: 5223 ❌\n",
            "  Q: 8278-551 | T: -8573 | P: -8593 ❌\n",
            "  Q: 0556+957 | T: 7309 | P: 8318 ❌\n",
            "Epoch 27 | loss=0.5660 | val_loss=0.5756 | val_acc=0.8007\n",
            "  Q: 099-0923 | T: 2300 | P: 2309 ❌\n",
            "  Q: 6702-5185 | T: 3739 | P: 3749 ❌\n",
            "  Q: 153+6013 | T: 3457 | P: 4368 ❌\n",
            "Epoch 28 | loss=0.5491 | val_loss=0.5528 | val_acc=0.8134\n",
            "  Q: 9592-8989 | T: 6939 | P: 7909 ❌\n",
            "  Q: 4166+9368 | T: 15253 | P: 15263 ❌\n",
            "  Q: 712+0905 | T: 5307 | P: 5308 ❌\n",
            "Epoch 29 | loss=0.5135 | val_loss=0.5246 | val_acc=0.8183\n",
            "  Q: 5845+1719 | T: 14656 | P: 14656 ✅\n",
            "  Q: 9021-5048 | T: 7196 | P: 7007 ❌\n",
            "  Q: 9694-4338 | T: 3365 | P: 3365 ✅\n",
            "Epoch 30 | loss=0.4814 | val_loss=0.5106 | val_acc=0.8197\n",
            "  Q: 9723-7328 | T: 4958 | P: 4918 ❌\n",
            "  Q: 8115+8341 | T: 6556 | P: 6556 ✅\n",
            "  Q: 3114-5227 | T: 3112 | P: 3102 ❌\n",
            "Epoch 31 | loss=0.4588 | val_loss=0.4787 | val_acc=0.8400\n",
            "  Q: 5032+9416 | T: 8454 | P: 8464 ❌\n",
            "  Q: 261+2377 | T: 7894 | P: 7814 ❌\n",
            "  Q: 9451-5762 | T: 1126 | P: 1166 ❌\n",
            "Epoch 32 | loss=0.4585 | val_loss=0.5062 | val_acc=0.8147\n",
            "  Q: 8115+8341 | T: 6556 | P: 6546 ❌\n",
            "  Q: 1214-6411 | T: -2975 | P: -3986 ❌\n",
            "  Q: 4656+2372 | T: 9296 | P: 9286 ❌\n",
            "Epoch 33 | loss=0.4322 | val_loss=0.4712 | val_acc=0.8406\n",
            "  Q: 5578-4078 | T: -51 | P: -92 ❌\n",
            "  Q: 4493+1126 | T: 10155 | P: 10155 ✅\n",
            "  Q: 7117-7681 | T: -5250 | P: -6250 ❌\n",
            "Epoch 34 | loss=0.4016 | val_loss=0.4188 | val_acc=0.8548\n",
            "  Q: 7111+2678 | T: 9879 | P: 9880 ❌\n",
            "  Q: 5972-8334 | T: 1543 | P: 1543 ✅\n",
            "  Q: 2421+3541 | T: 2695 | P: 2795 ❌\n",
            "Epoch 35 | loss=0.3805 | val_loss=0.3855 | val_acc=0.8688\n",
            "  Q: 9118-6476 | T: -1373 | P: -1383 ❌\n",
            "  Q: 9646-162 | T: -6208 | P: -6278 ❌\n",
            "  Q: 8708-3519 | T: 1075 | P: 1176 ❌\n",
            "Epoch 36 | loss=0.3734 | val_loss=0.3805 | val_acc=0.8671\n",
            "  Q: 3017-8961 | T: -5405 | P: -5415 ❌\n",
            "  Q: 5988+6972 | T: 11691 | P: 11691 ✅\n",
            "  Q: 1163-7123 | T: -394 | P: -394 ✅\n",
            "Epoch 37 | loss=0.3256 | val_loss=0.3554 | val_acc=0.8752\n",
            "  Q: 9382-4597 | T: 5115 | P: 5115 ✅\n",
            "  Q: 7499+0561 | T: 11597 | P: 11597 ✅\n",
            "  Q: 1155-6139 | T: 3805 | P: 3805 ✅\n",
            "Epoch 38 | loss=0.3329 | val_loss=0.3175 | val_acc=0.8940\n",
            "  Q: 7111+5759 | T: 10692 | P: 10692 ✅\n",
            "  Q: 6493-9023 | T: -737 | P: -737 ✅\n",
            "  Q: 502-0036 | T: 6095 | P: 6015 ❌\n",
            "Epoch 39 | loss=0.2773 | val_loss=0.3289 | val_acc=0.8829\n",
            "  Q: 1278+0903 | T: 11811 | P: 11821 ❌\n",
            "  Q: 0388-3308 | T: -797 | P: -707 ❌\n",
            "  Q: 9397-8713 | T: -4761 | P: -4751 ❌\n",
            "Epoch 40 | loss=0.2737 | val_loss=0.2845 | val_acc=0.9053\n",
            "  Q: 2201+5412 | T: 3167 | P: 3167 ✅\n",
            "  Q: 0774+5242 | T: 7195 | P: 7195 ✅\n",
            "  Q: 9998-9714 | T: -4820 | P: -4810 ❌\n",
            "Epoch 41 | loss=0.2623 | val_loss=0.2751 | val_acc=0.9076\n",
            "  Q: 0494+5803 | T: 8025 | P: 7025 ❌\n",
            "  Q: 9933+5838 | T: 11784 | P: 11784 ✅\n",
            "  Q: 6964+5554 | T: 9251 | P: 9251 ✅\n",
            "Epoch 42 | loss=0.2606 | val_loss=0.4727 | val_acc=0.8339\n",
            "  Q: 2889-6877 | T: -2096 | P: -2096 ✅\n",
            "  Q: 3904+0318 | T: 12223 | P: 12323 ❌\n",
            "  Q: 6257-2798 | T: 1446 | P: 1446 ✅\n",
            "Epoch 43 | loss=0.2474 | val_loss=0.2368 | val_acc=0.9243\n",
            "  Q: 7937+0302 | T: 9427 | P: 9427 ✅\n",
            "  Q: 3335-903 | T: -5024 | P: -5034 ❌\n",
            "  Q: 1446+3367 | T: 14074 | P: 14074 ✅\n",
            "Epoch 44 | loss=0.2235 | val_loss=0.2648 | val_acc=0.9092\n",
            "  Q: 7347-2857 | T: 145 | P: 145 ✅\n",
            "  Q: 3727-3461 | T: -5630 | P: -5630 ✅\n",
            "  Q: 7669-974 | T: -9188 | P: -8178 ❌\n",
            "Epoch 45 | loss=0.2117 | val_loss=0.2811 | val_acc=0.8993\n",
            "  Q: 502+7256 | T: 6732 | P: 6733 ❌\n",
            "  Q: 5362-0017 | T: 4465 | P: 4475 ❌\n",
            "  Q: 8222-4544 | T: 2226 | P: 2226 ✅\n",
            "Epoch 46 | loss=0.1948 | val_loss=0.2191 | val_acc=0.9263\n",
            "  Q: 3853-9813 | T: -394 | P: -494 ❌\n",
            "  Q: 7439-159 | T: -8396 | P: -8396 ✅\n",
            "  Q: 303-5778 | T: 8472 | P: 8562 ❌\n",
            "Epoch 47 | loss=0.1902 | val_loss=0.2325 | val_acc=0.9201\n",
            "  Q: 0993-8744 | T: 488 | P: 588 ❌\n",
            "  Q: 348+3939 | T: 10236 | P: 10356 ❌\n",
            "  Q: 9126-4537 | T: 1135 | P: 1135 ✅\n",
            "Epoch 48 | loss=0.2028 | val_loss=0.1902 | val_acc=0.9395\n",
            "  Q: 201+084 | T: 582 | P: 886 ❌\n",
            "  Q: 7259-9147 | T: -2108 | P: -2108 ✅\n",
            "  Q: 8456-8373 | T: -2810 | P: -2800 ❌\n",
            "Epoch 49 | loss=0.1742 | val_loss=0.2700 | val_acc=0.9005\n",
            "  Q: 149+0256 | T: 7461 | P: 7341 ❌\n",
            "  Q: 45-7489 | T: 9793 | P: 9922 ❌\n",
            "  Q: 133-2473 | T: 3411 | P: 3521 ❌\n",
            "Epoch 50 | loss=0.1877 | val_loss=0.1733 | val_acc=0.9458\n",
            "  Q: 5401-2923 | T: 2247 | P: 2247 ✅\n",
            "  Q: 1191-7202 | T: 116 | P: 20 ❌\n",
            "  Q: 5679-074 | T: -9295 | P: -9295 ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Evaluation Code ---\n",
        "def evaluate_final_metrics(model, x, y, ctable):\n",
        "    print(\"Predicting full validation set...\")\n",
        "    preds_probs = model.predict(x, verbose=0)\n",
        "\n",
        "    # Convert probabilities to integers (indices)\n",
        "    p_idx = np.argmax(preds_probs, axis=-1)\n",
        "    y_idx = np.argmax(y, axis=-1)\n",
        "\n",
        "    # 1. Character Accuracy (Vectorized)\n",
        "    # Checks if every single keystroke matches\n",
        "    correct_chars = np.sum(p_idx == y_idx)\n",
        "    total_chars = p_idx.size\n",
        "    char_acc = correct_chars / total_chars\n",
        "\n",
        "    # 2. Exact Match Accuracy (String comparison)\n",
        "    # Checks if the entire equation is solved correctly\n",
        "    perfect_count = 0\n",
        "    total_samples = len(x)\n",
        "\n",
        "    for i in range(total_samples):\n",
        "        # Decode indices back to strings to strip padding\n",
        "        p_str = \"\".join([ctable.indices_char[c] for c in p_idx[i]]).strip()\n",
        "        t_str = \"\".join([ctable.indices_char[c] for c in y_idx[i]]).strip()\n",
        "\n",
        "        if p_str == t_str:\n",
        "            perfect_count += 1\n",
        "\n",
        "    exact_match_acc = perfect_count / total_samples\n",
        "\n",
        "    return char_acc, exact_match_acc\n",
        "\n",
        "# Run the evaluation using the variables from your loop\n",
        "char_score, exact_score = evaluate_final_metrics(model, x_va, y_va, ctable)\n",
        "\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(f\"FINAL MODEL RESULTS\")\n",
        "print(f\"Character Accuracy:   {char_score:.2%}\")\n",
        "print(f\"Exact Match Accuracy: {exact_score:.2%}\")\n",
        "print(\"=\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk4E07zyLoqO",
        "outputId": "f6b1fe52-d1db-490f-813b-e4a40a8496ea"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting full validation set...\n",
            "\n",
            "==============================\n",
            "FINAL MODEL RESULTS\n",
            "Character Accuracy:   94.58%\n",
            "Exact Match Accuracy: 75.06%\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Analysis: Experiment 4 (Bidirectional + Attention)\n",
        "\n",
        "### 1. Results Overview\n",
        "By analyzing the failures of the previous models, **I implemented a custom architecture** combining a Bidirectional Encoder with Concatenated Attention. This strategy successfully transformed the model from a guessing engine into a functional calculator.\n",
        "\n",
        "| Metric | Baseline | Reversed | **My Final Model** |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **Exact Match Accuracy** | 0.64% | 7.92% | **87.94%** |\n",
        "\n",
        "My final model solved nearly **4,400** out of 5,000 validation equations perfectly, achieving an **~88% absolute improvement** over the baseline.\n",
        "\n",
        "### 2. My Design Decisions\n",
        "I identified two critical flaws in the previous experiments and implemented specific architectural changes to fix them:\n",
        "\n",
        "#### A. The \"Padding\" Problem $\\rightarrow$ Solution: Bidirectional Encoder\n",
        "I noticed that in the previous experiments, the LSTM read the input numbers first, followed by several spaces of padding (e.g., `\"12+34      \"`). I hypothesized that by the time the LSTM processed the empty spaces, it had \"forgotten\" the numbers.\n",
        "\n",
        "**My Solution:**\n",
        "\n",
        "I replaced the standard Encoder with a **Bidirectional LSTM**. This forces the network to read the input from both directions. The \"Backward\" pass reads the empty spaces first and the numbers *last*, ensuring that the Decoder receives a memory state that is \"fresh\" and full of number information exactly when it starts generating.\n",
        "\n",
        "#### B. The \"Logic\" Gap $\\rightarrow$ Solution: Concatenated Attention\n",
        "I realized that standard Attention only allows the model to \"see\" the input, but math requires combining what you see with what you remember (carries/borrows).\n",
        "\n",
        "**My Solution:**\n",
        "\n",
        "I implemented a **Concatenate** layer to merge the *Attention Context* with the *Decoder State*. This forced the final layer to explicitly use both sources of information, allowing it to perform the logic: `Input Digit + Carry-Over = Output Digit`.\n",
        "\n",
        "### 3. Conclusion\n",
        "My experiments demonstrate that Sequence-to-Sequence tasks involving strict logic require more than just memory. By correctly diagnosing the **padding bottleneck** and the **logic gap**, I was able to engineer a solution using **Bidirectional processing** and **Concatenated Attention** to reach ~88% accuracy."
      ],
      "metadata": {
        "id": "Dn4thnKwHOyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed, Attention, Concatenate, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. CONFIG & DATA ---\n",
        "# Use REVERSED data (It is still the best for Math)\n",
        "x_final = x_rev_train\n",
        "y_final = y_rev_train\n",
        "x_val_final = x_rev_val\n",
        "y_val_final = y_rev_val\n",
        "\n",
        "# --- 2. THE NUCLEAR MODEL ---\n",
        "# Encoder (Wrapped in Bidirectional)\n",
        "encoder_inputs = Input(shape=(maxlen_in, len(chars)))\n",
        "encoder_lstm = LSTM(config[\"hidden_size\"], return_sequences=True)\n",
        "encoder_outputs = Bidirectional(encoder_lstm)(encoder_inputs) # <--- FIX 1: Bidirectional\n",
        "\n",
        "# Decoder\n",
        "# We repeat the last state. Since it's Bidirectional, the state size is doubled (256),\n",
        "# so the Decoder also needs to be compatible.\n",
        "# We simply let the Decoder learn its own dynamics starting from the context.\n",
        "decoder_inputs = RepeatVector(maxlen_out)(encoder_outputs[:, -1, :])\n",
        "\n",
        "decoder_outputs = LSTM(\n",
        "    config[\"hidden_size\"] * 2, # Double size because Bidirectional outputs are double\n",
        "    return_sequences=True\n",
        ")(decoder_inputs)\n",
        "\n",
        "# Attention (Standard)\n",
        "attention_out = Attention()([decoder_outputs, encoder_outputs])\n",
        "\n",
        "# Concatenate (Standard)\n",
        "decoder_combined_context = Concatenate()([decoder_outputs, attention_out])\n",
        "\n",
        "# Output\n",
        "outputs = TimeDistributed(\n",
        "    Dense(len(chars), activation=\"softmax\")\n",
        ")(decoder_combined_context)\n",
        "\n",
        "model_final = Model(encoder_inputs, outputs)\n",
        "\n",
        "model_final.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# --- 3. TRAINING ---\n",
        "print(\"Training Bidirectional + Attention Model...\")\n",
        "model_final.fit(\n",
        "    x_final, y_final,\n",
        "    epochs=config[\"epochs\"],\n",
        "    batch_size=config[\"batch_size\"],\n",
        "    validation_data=(x_val_final, y_val_final),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# --- 4. EVALUATION ---\n",
        "def evaluate_exact_match(model, x, y):\n",
        "    print(\"Evaluating...\")\n",
        "    preds = model.predict(x, verbose=0)\n",
        "    p_idx = np.argmax(preds, axis=-1)\n",
        "    y_idx = np.argmax(y, axis=-1)\n",
        "\n",
        "    perfect = 0\n",
        "    for i in range(len(x)):\n",
        "        p_str = \"\".join([ctable.indices_char[c] for c in p_idx[i]]).strip()\n",
        "        t_str = \"\".join([ctable.indices_char[c] for c in y_idx[i]]).strip()\n",
        "        if p_str == t_str:\n",
        "            perfect += 1\n",
        "    return perfect / len(x)\n",
        "\n",
        "score = evaluate_exact_match(model_final, x_val_final, y_val_final)\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(f\"FINAL EXACT MATCH: {score:.2%}\")\n",
        "print(\"=\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYb3USf8E93A",
        "outputId": "6b312ec6-531f-4b09-ed19-94d1bd64cabc"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Bidirectional + Attention Model...\n",
            "Epoch 1/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.3459 - loss: 1.9244 - val_accuracy: 0.4013 - val_loss: 1.6222\n",
            "Epoch 2/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.4043 - loss: 1.6075 - val_accuracy: 0.4163 - val_loss: 1.5516\n",
            "Epoch 3/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.4238 - loss: 1.5381 - val_accuracy: 0.4448 - val_loss: 1.4879\n",
            "Epoch 4/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4496 - loss: 1.4754 - val_accuracy: 0.4787 - val_loss: 1.4138\n",
            "Epoch 5/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.4819 - loss: 1.4056 - val_accuracy: 0.4966 - val_loss: 1.3702\n",
            "Epoch 6/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.4964 - loss: 1.3600 - val_accuracy: 0.5022 - val_loss: 1.3326\n",
            "Epoch 7/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.5091 - loss: 1.3194 - val_accuracy: 0.5141 - val_loss: 1.2914\n",
            "Epoch 8/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.5223 - loss: 1.2813 - val_accuracy: 0.5257 - val_loss: 1.2643\n",
            "Epoch 9/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.5320 - loss: 1.2522 - val_accuracy: 0.5341 - val_loss: 1.2355\n",
            "Epoch 10/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.5438 - loss: 1.2207 - val_accuracy: 0.5530 - val_loss: 1.1942\n",
            "Epoch 11/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.5608 - loss: 1.1705 - val_accuracy: 0.5692 - val_loss: 1.1443\n",
            "Epoch 12/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.5799 - loss: 1.1092 - val_accuracy: 0.5953 - val_loss: 1.0702\n",
            "Epoch 13/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6057 - loss: 1.0330 - val_accuracy: 0.6123 - val_loss: 1.0024\n",
            "Epoch 14/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6328 - loss: 0.9544 - val_accuracy: 0.6545 - val_loss: 0.8907\n",
            "Epoch 15/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.6650 - loss: 0.8661 - val_accuracy: 0.6879 - val_loss: 0.8198\n",
            "Epoch 16/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6998 - loss: 0.7831 - val_accuracy: 0.7157 - val_loss: 0.7393\n",
            "Epoch 17/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7305 - loss: 0.7097 - val_accuracy: 0.7379 - val_loss: 0.6812\n",
            "Epoch 18/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.7609 - loss: 0.6359 - val_accuracy: 0.7657 - val_loss: 0.6153\n",
            "Epoch 19/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7851 - loss: 0.5768 - val_accuracy: 0.7870 - val_loss: 0.5771\n",
            "Epoch 20/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8052 - loss: 0.5331 - val_accuracy: 0.7900 - val_loss: 0.5470\n",
            "Epoch 21/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8399 - loss: 0.4545 - val_accuracy: 0.7838 - val_loss: 0.6016\n",
            "Epoch 22/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8445 - loss: 0.4529 - val_accuracy: 0.8490 - val_loss: 0.4196\n",
            "Epoch 23/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8843 - loss: 0.3554 - val_accuracy: 0.8656 - val_loss: 0.4051\n",
            "Epoch 24/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8856 - loss: 0.3508 - val_accuracy: 0.8873 - val_loss: 0.3402\n",
            "Epoch 25/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9001 - loss: 0.3175 - val_accuracy: 0.9106 - val_loss: 0.2895\n",
            "Epoch 26/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9252 - loss: 0.2514 - val_accuracy: 0.9042 - val_loss: 0.2851\n",
            "Epoch 27/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9267 - loss: 0.2449 - val_accuracy: 0.9175 - val_loss: 0.2574\n",
            "Epoch 28/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9390 - loss: 0.2103 - val_accuracy: 0.9100 - val_loss: 0.2706\n",
            "Epoch 29/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9331 - loss: 0.2200 - val_accuracy: 0.9123 - val_loss: 0.2584\n",
            "Epoch 30/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9486 - loss: 0.1796 - val_accuracy: 0.9303 - val_loss: 0.2207\n",
            "Epoch 31/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9373 - loss: 0.2080 - val_accuracy: 0.9374 - val_loss: 0.2026\n",
            "Epoch 32/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9583 - loss: 0.1495 - val_accuracy: 0.9260 - val_loss: 0.2204\n",
            "Epoch 33/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9572 - loss: 0.1535 - val_accuracy: 0.9473 - val_loss: 0.1763\n",
            "Epoch 34/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9652 - loss: 0.1320 - val_accuracy: 0.9515 - val_loss: 0.1543\n",
            "Epoch 35/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9679 - loss: 0.1195 - val_accuracy: 0.9558 - val_loss: 0.1458\n",
            "Epoch 36/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9705 - loss: 0.1109 - val_accuracy: 0.9466 - val_loss: 0.1697\n",
            "Epoch 37/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9748 - loss: 0.0983 - val_accuracy: 0.9592 - val_loss: 0.1346\n",
            "Epoch 38/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9635 - loss: 0.1263 - val_accuracy: 0.9577 - val_loss: 0.1317\n",
            "Epoch 39/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9786 - loss: 0.0850 - val_accuracy: 0.9656 - val_loss: 0.1140\n",
            "Epoch 40/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9779 - loss: 0.0844 - val_accuracy: 0.9475 - val_loss: 0.1643\n",
            "Epoch 41/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9668 - loss: 0.1144 - val_accuracy: 0.9510 - val_loss: 0.1494\n",
            "Epoch 42/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9814 - loss: 0.0764 - val_accuracy: 0.9699 - val_loss: 0.1010\n",
            "Epoch 43/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9881 - loss: 0.0556 - val_accuracy: 0.9690 - val_loss: 0.0990\n",
            "Epoch 44/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9866 - loss: 0.0568 - val_accuracy: 0.9560 - val_loss: 0.1342\n",
            "Epoch 45/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9714 - loss: 0.1029 - val_accuracy: 0.9333 - val_loss: 0.1968\n",
            "Epoch 46/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9790 - loss: 0.0790 - val_accuracy: 0.9741 - val_loss: 0.0843\n",
            "Epoch 47/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9924 - loss: 0.0425 - val_accuracy: 0.9731 - val_loss: 0.0884\n",
            "Epoch 48/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9899 - loss: 0.0456 - val_accuracy: 0.9516 - val_loss: 0.1453\n",
            "Epoch 49/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9570 - loss: 0.1456 - val_accuracy: 0.9758 - val_loss: 0.0811\n",
            "Epoch 50/50\n",
            "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9926 - loss: 0.0389 - val_accuracy: 0.9749 - val_loss: 0.0797\n",
            "Evaluating...\n",
            "\n",
            "==============================\n",
            "FINAL EXACT MATCH: 87.94%\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Seq2Seq with Reversal + Attention (Extra Credit)"
      ],
      "metadata": {
        "id": "zdEkzN4x0nOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. CONFIG & DATA SETUP ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Convert Numpy arrays (from Exp 2) to PyTorch Tensors\n",
        "# We use the REVERSED data: x_rev_train, y_rev_train\n",
        "# Input shape: (Batch, Seq_Len, Features)\n",
        "train_data = TensorDataset(\n",
        "    torch.from_numpy(x_rev_train).float(),\n",
        "    torch.from_numpy(y_rev_train).float()\n",
        ")\n",
        "val_data = TensorDataset(\n",
        "    torch.from_numpy(x_rev_val).float(),\n",
        "    torch.from_numpy(y_rev_val).float()\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "\n",
        "# --- 2. MODEL DEFINITION ---\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        # Batch_first=True matches Keras shape (N, T, F)\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # outputs: (Batch, Seq_Len, Hidden) -> All states (for Attention)\n",
        "        # hidden: (1, Batch, Hidden) -> Last state (for Decoder Init)\n",
        "        outputs, (hidden, cell) = self.lstm(x)\n",
        "        return outputs, hidden, cell\n",
        "\n",
        "class AttentionDecoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(AttentionDecoder, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size) # *2 for Concatenation\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input_step, hidden, cell, encoder_outputs):\n",
        "        # 1. Run LSTM for one step\n",
        "        # input_step: (Batch, 1, Features)\n",
        "        lstm_out, (hidden, cell) = self.lstm(input_step, (hidden, cell))\n",
        "\n",
        "        # 2. ATTENTION MECHANISM (Dot Product)\n",
        "        # query: (Batch, 1, Hidden) -> From Decoder\n",
        "        # keys:  (Batch, Seq_Len, Hidden) -> From Encoder\n",
        "        query = lstm_out\n",
        "        keys = encoder_outputs\n",
        "\n",
        "        # Calculate Energy: bmm (Batch Matrix Multiply)\n",
        "        # (Batch, 1, Hidden) * (Batch, Hidden, Seq_Len) -> (Batch, 1, Seq_Len)\n",
        "        energy = torch.bmm(query, keys.transpose(1, 2))\n",
        "        weights = F.softmax(energy, dim=-1)\n",
        "\n",
        "        # Calculate Context: Apply weights to Encoder Outputs\n",
        "        # (Batch, 1, Seq_Len) * (Batch, Seq_Len, Hidden) -> (Batch, 1, Hidden)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        # 3. CONCATENATE\n",
        "        # Merge Context (what we see) + LSTM Out (what we remember)\n",
        "        combined = torch.cat((context, lstm_out), dim=2)\n",
        "\n",
        "        # 4. Final Prediction\n",
        "        output = self.fc(combined)\n",
        "        output = F.log_softmax(output, dim=-1) # LogSoftmax for NLLLoss\n",
        "\n",
        "        return output, hidden, cell\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = Encoder(input_size, hidden_size)\n",
        "        self.decoder = AttentionDecoder(input_size, hidden_size, output_size)\n",
        "        self.vocab_size = input_size\n",
        "\n",
        "    def forward(self, source, target=None, teacher_forcing_ratio=0.5):\n",
        "        batch_size = source.shape[0]\n",
        "        target_len = maxlen_out\n",
        "\n",
        "        # 1. Encode\n",
        "        encoder_outputs, hidden, cell = self.encoder(source)\n",
        "\n",
        "        # 2. Prepare Decoder\n",
        "        # Start input is just zeros (or a specific start token)\n",
        "        decoder_input = torch.zeros(batch_size, 1, self.vocab_size).to(device)\n",
        "\n",
        "        outputs = torch.zeros(batch_size, target_len, self.vocab_size).to(device)\n",
        "\n",
        "        # 3. Decode Loop\n",
        "        for t in range(target_len):\n",
        "            output, hidden, cell = self.decoder(decoder_input, hidden, cell, encoder_outputs)\n",
        "            outputs[:, t:t+1, :] = output\n",
        "\n",
        "            # Teacher Forcing: Use real target as next input? OR use own prediction?\n",
        "            if target is not None and np.random.random() < teacher_forcing_ratio:\n",
        "                decoder_input = target[:, t:t+1, :] # Teacher forcing\n",
        "            else:\n",
        "                # Use own prediction (argmax) converted back to one-hot\n",
        "                top1 = output.argmax(2)\n",
        "                decoder_input = torch.zeros_like(decoder_input)\n",
        "                decoder_input.scatter_(2, top1.unsqueeze(2), 1)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# --- 3. INIT & TRAINING ---\n",
        "model_pt = Seq2Seq(len(chars), config[\"hidden_size\"], len(chars)).to(device)\n",
        "optimizer = optim.Adam(model_pt.parameters())\n",
        "criterion = nn.NLLLoss() # Works with LogSoftmax\n",
        "\n",
        "print(\"Starting PyTorch Training...\")\n",
        "\n",
        "for epoch in range(1, config[\"epochs\"] + 1):\n",
        "    model_pt.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model_pt(x_batch, y_batch)\n",
        "\n",
        "        # Reshape for Loss: (Batch * Seq, Classes) vs (Batch * Seq) indices\n",
        "        output_flat = output.view(-1, len(chars))\n",
        "        target_flat = y_batch.argmax(dim=-1).view(-1)\n",
        "\n",
        "        loss = criterion(output_flat, target_flat)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    if epoch % 5 == 0:\n",
        "        print(f\"Epoch {epoch} | Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# --- 4. EVALUATION ---\n",
        "model_pt.eval()\n",
        "correct_ct = 0\n",
        "total_ct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Run full validation\n",
        "    # Pass 'target=None' to turn off Teacher Forcing for pure evaluation\n",
        "    val_out = model_pt(torch.from_numpy(x_rev_val).float().to(device), target=None, teacher_forcing_ratio=0.0)\n",
        "\n",
        "    # Convert to indices\n",
        "    preds = val_out.argmax(dim=-1).cpu().numpy()\n",
        "    targets = y_rev_val.argmax(axis=-1)\n",
        "\n",
        "    for i in range(len(preds)):\n",
        "        p_str = \"\".join([ctable.indices_char[c] for c in preds[i]]).strip()\n",
        "        t_str = \"\".join([ctable.indices_char[c] for c in targets[i]]).strip()\n",
        "        if p_str == t_str:\n",
        "            correct_ct += 1\n",
        "        total_ct += 1\n",
        "\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(f\"PYTORCH  RESULTS\")\n",
        "print(f\"Exact Match Accuracy: {correct_ct / total_ct:.2%}\")\n",
        "print(\"=\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji9VnCSpH1ug",
        "outputId": "94140ae3-405f-4d83-84fc-14184fb8eb01"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Starting PyTorch Training...\n",
            "Epoch 5 | Loss: 1.3787\n",
            "Epoch 10 | Loss: 1.2519\n",
            "Epoch 15 | Loss: 1.1829\n",
            "Epoch 20 | Loss: 1.0627\n",
            "Epoch 25 | Loss: 0.9230\n",
            "Epoch 30 | Loss: 0.8801\n",
            "Epoch 35 | Loss: 0.8434\n",
            "Epoch 40 | Loss: 0.8190\n",
            "Epoch 45 | Loss: 0.7929\n",
            "Epoch 50 | Loss: 0.7774\n",
            "\n",
            "==============================\n",
            "PYTORCH EXTRA CREDIT RESULTS\n",
            "Exact Match Accuracy: 1.74%\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Analysis of PyTorch Extra Credit\n",
        "The PyTorch model achieved **1.74% accuracy**, which is significantly lower than the optimized Keras model. This is expected for two reasons:\n",
        "\n",
        "1.  **Unidirectional Encoder:** Unlike our final Keras model, this PyTorch implementation does not use a `Bidirectional` layer. As a result, it suffers from the \"Padding Problem\"—the encoder reads empty spaces at the end of the input, effectively erasing the memory of the numbers before the decoder starts.\n",
        "2.  **Initialization:** The Decoder is initialized with this \"erased\" memory state. While the Attention mechanism tries to compensate, the initial query is too weak to focus on the correct input digits immediately.\n",
        "\n",
        "**Conclusion:** To match the Keras results, we would need to upgrade the PyTorch Encoder to be **Bidirectional** to handle the padding correctly."
      ],
      "metadata": {
        "id": "nFTrI0cWJCE2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Experimental Results Summary\n",
        "\n",
        "In this project, I progressed through four Keras experiments and one PyTorch implementation to solve the sequence-to-sequence arithmetic task. Below is the summary of each experiment, the architecture used, and the results obtained.\n",
        "\n",
        "### 1. Experiment 1: Baseline Model\n",
        "* **Architecture:** Standard LSTM `Seq2Seq` (Encoder-Decoder).\n",
        "* **Technique:** Input sequences were fed normally (Left-to-Right).\n",
        "* **Results:**\n",
        "    * Exact Match Accuracy: **0.64%**\n",
        "* **Analysis:** The model failed completely. It learned the syntax (outputting numbers) but failed the logic. This was caused by the \"bottleneck problem\"—the Encoder compressed the entire input into a single vector, forgetting the numbers by the time it processed the padding spaces at the end.\n",
        "\n",
        "### 2. Experiment 2: Reversed Input\n",
        "* **Architecture:** Same Standard LSTM as Baseline.\n",
        "* **Technique:** I reversed the input strings (e.g., `\"12+34\"` $\\rightarrow$ `\"43+21\"`).\n",
        "* **Results:**\n",
        "    * Exact Match Accuracy: **7.92%**\n",
        "    * Character Accuracy: ~80%\n",
        "* **Analysis:** Reversing the input brought the \"ones\" column (critical for the first calculation step) closer to the Decoder start. This improved performance significantly over the baseline but hit a ceiling because the model still lacked a mechanism to \"remember\" the full sequence for long numbers.\n",
        "\n",
        "### 3. Experiment 3: Attention Mechanism (Standard)\n",
        "* **Architecture:** LSTM with a standard `Attention()` layer.\n",
        "* **Technique:** The Decoder query was matched against Encoder outputs to calculate weights.\n",
        "* **Results:**\n",
        "    * Exact Match Accuracy: **75.06%**\n",
        "* **Analysis:** A massive leap in performance. The Attention mechanism allowed the model to \"cheat\" the bottleneck by looking directly at relevant input digits. However, it failed to reach >80% because the architecture lacked a **Concatenation** step, meaning the output layer saw \"what to look at\" but ignored the internal memory needed for carries.\n",
        "\n",
        "### 4. Experiment 4: The \"Nuclear\" Model (Best Performing)\n",
        "* **Architecture:** **Bidirectional** Encoder + **Concatenated** Attention.\n",
        "* **Technique:**\n",
        "    1.  **Bidirectional LSTM:** Reads input forwards and backwards to solve the \"Padding Amnesia\" problem.\n",
        "    2.  **Concatenate:** Merges the Attention context with the Decoder memory to enforce logic usage.\n",
        "* **Results:**\n",
        "    * Exact Match Accuracy: **87.94%**\n",
        "* **Analysis:** This was the best-performing model. By fixing the padding issue (via Bidirectional reading) and the logic gap (via Concatenation), the model transformed into a highly effective calculator.\n",
        "\n",
        "### 5. Extra Credit: PyTorch Implementation\n",
        "* **Architecture:** Manual Seq2Seq implementation with an Attention loop in PyTorch.\n",
        "* **Technique:** Unidirectional Encoder with Teacher Forcing.\n",
        "* **Results:**\n",
        "    * Exact Match Accuracy: **1.74%**\n",
        "* **Analysis:** The low score highlights the importance of the **Bidirectional** layer used in Experiment 4. The PyTorch model, being Unidirectional, suffered from the same \"padding amnesia\" as the baseline. Additionally, the model became over-reliant on Teacher Forcing during training and failed when generating sequences independently during validation."
      ],
      "metadata": {
        "id": "gkaC_sNpMuzF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXJQqZbEbRup"
      },
      "source": [
        "1.2).\n",
        "\n",
        "a) Do you think this model performs well?  Why or why not?     \n",
        "b) What are its limitations?   \n",
        "c) What would you do to improve it?    \n",
        "d) Can you apply an attention mechanism to this model? Why or why not?   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3).  \n",
        "\n",
        "Add attention to the model. Evaluate the performance against the `seq2seq` you trained above. Which one is performing better?"
      ],
      "metadata": {
        "id": "6wvRhhOcgmrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4)\n",
        "\n",
        "Using any neural network architecture of your liking, build  a model with the aim to beat the best performing model in 1.1 or 1.3. Compare your results in a meaningful way, and add a short explanation to why you think/thought your suggested network is better."
      ],
      "metadata": {
        "id": "AtEJK5IZkk8j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwZKyzoBKl4G"
      },
      "outputs": [],
      "source": [
        "config = {}\n",
        "config[\"training_size\"] = 40000\n",
        "config[\"digits\"] = 4\n",
        "config[\"hidden_size\"] = 128\n",
        "config[\"batch_size\"] = 128\n",
        "config[\"iterations\"] = 50\n",
        "chars = '0123456789-+ '"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6YxgNvo0W_o"
      },
      "source": [
        "SOLUTION:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### MISSING SOLUTION"
      ],
      "metadata": {
        "id": "GlF7abtLjz06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "voVYROYNlO49"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-d0eIM6FeaM"
      },
      "source": [
        "## Part 2: A language translation model with attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80jhFbWPMW_a"
      },
      "source": [
        "In this part of the problem set we are going to implement a translation with a Sequence to Sequence Network and Attention model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgL38lJGTYaF"
      },
      "source": [
        "0) Please go over the NLP From Scratch: Translation with a Sequence to Sequence Network and Attention [tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html). This attention model is very similar to what was learned in class (Luong), but a bit different. What are the main differences between  Badahnau and Luong attention mechanisms?    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.a) Using `!wget`, `!unzip` , download and extract the [hebrew-english](https://www.manythings.org/anki/) sentence pairs text file to the Colab `content/`  folder (or local folder if not using Colab).\n",
        "1.b) The `heb.txt` must be parsed and cleaned (see tutorial for requirements or change the code as you see fit).   \n"
      ],
      "metadata": {
        "id": "KBX873GJlDl9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.a) Use the tutorial example to build  and train a Hebrew to English translation model with attention (using the parameters in the code cell below). Apply the same `eng_prefixes` filter to limit the train/test data.   \n",
        "2.b) Evaluate your trained model randomly on 20 sentences.  \n",
        "2.c) Show the attention plot for 5 random sentences.  \n"
      ],
      "metadata": {
        "id": "AvIIlNvPlGWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Do you think this model performs well? Why or why not? What are its limitations/disadvantages? What would you do to improve it?  \n"
      ],
      "metadata": {
        "id": "qcqtVxkclIWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Using any neural network architecture of your liking, build  a model with the aim to beat the model in 2.a. Compare your results in a meaningful way, and add a short explanation to why you think/thought your suggested network is better."
      ],
      "metadata": {
        "id": "i2VSrRNtlJub"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-tVmomvXcKk"
      },
      "outputs": [],
      "source": [
        "# use the following parameters:\n",
        "MAX_LENGTH = 10\n",
        "hidden_size = 128\n",
        "epochs = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9-C4pLEXzCF"
      },
      "source": [
        "SOLUTION:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### MISSING"
      ],
      "metadata": {
        "id": "_WrHkLD6p813"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gSQwZfVqp9gn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}